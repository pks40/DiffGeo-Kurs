% !TeX spellcheck = de_DE
\documentclass[a4paper]{scrreprt}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[sc]{mathpazo}
\linespread{1.05}
\usepackage{exscale} % To scale mathematical symbols correctly while using T1
\usepackage{amsmath,amsthm,amssymb,dsfont}
\usepackage{tikz}
	\usetikzlibrary{matrix}
\usepackage[ngerman]{babel}
\usepackage{enumitem}
\usepackage{microtype} % Microtypography!
\usepackage{epigraph}
\usepackage{hyperref}
\usepackage{todonotes}

\setlength{\epigraphwidth}{0.6\textwidth}

\numberwithin{equation}{chapter}

\newcommand{\D}{\mathrm{d}}
\newcommand{\DD}{\mathrm{D}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\diff}{:\Longleftrightarrow}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Diff}{Diff}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\pr}{pr}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\tr}{tr}

\newcommand{\R}{\mathbb{R}}
\newcommand{\sC}{\mathcal{C}^{\infty}}
\newcommand{\sm}{\mathcal{F}}
\newcommand{\vf}{\mathfrak{X}}
\newcommand{\tril}{\vartriangleleft}
\newcommand{\trir}{\vartriangleright}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{lemma}[defn]{Lemma}
\newtheorem{prop}[defn]{Proposition}
\newtheorem{satz}[defn]{Satz}
\newtheorem{kor}[defn]{Korollar}
\newtheorem{bem}[defn]{Bemerkung}
\newtheorem{bsp}[defn]{Beispiel}
\newtheorem{nota}[defn]{Notation}

\newcommand{\bewUeb}{\begin{proof}Übung.\end{proof}}

% Kommentare
\newcommand{\kommP}[2][noinline]{\todo[#1,color=green!40]{#2}}
\newcommand{\kommB}[2][noinline]{\todo[#1,color=blue!20]{#2}}

\title{Einführung in die Differentialgeometrie}
\subtitle{Kurs auf der CdE-WinterAkademie 2018/19}
\author{Benjamin Haake, Philip Schwartz}
\date{November 2018}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{chapter}{-1}
\chapter{Einleitung}
\epigraph{Differentialgeometrie ist die Lehre von Eigenschaften, die invariant unter Notationswechsel sind.}{\textsc{Altes chinesisches Sprichwort}}

Verallgemeinerung von Kurven, Flächen und so. Extrem wichtig innerhalb der Mathematik und auch in quasi allen Anwendungsgebieten, insb. der theoretischen Physik (ART, Eichtheorien, alles!).

\section{Bekannte Konzepte, Notationen etc.}

\subsection{Lineare Algebra}

\begin{nota}
	Für einen Vektorraum $V$ über einem Körper $K$ bezeichnet \[V^* := \mathrm{Hom}(V,K) = \{f\colon V \to K : f \text{ linear}\}\] den Dualraum von $V$.
\end{nota}

\subsection{Mehrdimensionale Analysis}
\begin{nota}
	Punkte im $\mathbb R^n$ schreiben wir als $a = (a^1, \dots, a^n)$. Die Vektoren der Standardbasis von $\mathbb R^n$ schreiben wir als $\e_1, \dots, \e_n \in \mathbb R^n$, also \[\e_i = (0,\dots,\underset{i}{1},\dots,0).\]

	Sei $U \subset \mathbb R^n$ eine offene Menge und $f\colon U \to \mathbb R$ eine differenzierbare Abbildung. Die partielle Ableitung von $f$ nach der $i$-ten Komponente schreiben wir als $\partial_i f$, d.\,h. es ist
	\[(\partial_i f)(a) = \left.\frac{\D f(a + h \e_i)}{\D h}\right|_{h=0} = \lim_{h\to 0} \frac{f(a + h \e_i) - f(a)}{h}.\]
\end{nota}

\begin{satz}[Mehrdimensionale Kettenregel]
	Seien $U \subset \mathbb R^l, V \subset \mathbb R^m, W \subset \mathbb R^n$ offene Mengen und $f\colon U\to V, g\colon V \to W$ differenzierbare Abbildungen. Dann ist auch $g\circ f\colon U \to W$ differenzierbar, und für die Differentiale gilt
	\[\DD(g\circ f)|_a = \DD g|_{f(a)} \circ \DD f|_a\]
	für $a \in U$. Für die partiellen Ableitungen der Komponenten gilt also
	\[\partial_i(g\circ f) = \sum_{j = 1}^m ((\partial_j g)\circ f) \cdot \partial_i f^j,\]
	d.\,h.
	\[(\partial_i(g\circ f))(a) = \sum_{j = 1}^m (\partial_j g)(f(a)) \cdot (\partial_i f^j)(a).\]
\end{satz}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Mannigfaltigkeiten}
	\section{Topologie}
		\begin{defn}[Topologischer Raum]
			Ein Tupel $(X,\mathcal{T})$ bestehend aus einer Menge $X$ und einer Familie von Teilmengen $\mathcal{T}$ heißt \emph{topologischer Raum}, wenn folgende Eigenschaften erfüllt sind:
			\begin{enumerate}[label=$T$\arabic*]
				\item $\emptyset, x\in \mathcal{T}$
				\item $\forall U_1, U_2\in \mathcal{T} \text{ gilt }U_1\cap U_2\in\mathcal{T}$
				\item Für jede Familie $\lbrace U_i\rbrace_{i\in I}\subset \mathcal{T}$ gilt $\bigcup_{i\in I}U_i\in\mathcal{T}$
			\end{enumerate}
			Die Familie $\mathcal{T}$ heißt \emph{Topologie} auf der Menge $X$, ihre Elemente heißen \emph{offene Mengen}. Eine Menge heißt \emph{abgeschlossen}, wenn ihr Komplement offen ist.
		\end{defn}
		\begin{defn}[Basis einer Topologie]
			Eine Familie offener Mengen $\lbrace B_i\rbrace_{i\in I}\subset \mathcal{T}$ heißt \emph{Basis} eines topologischen Raums $(X,\mathcal{T})$, wenn sich jede offene Menge als Vereinigung von Elementen der Basis schreiben lässt, das heißt:
			\begin{equation*}
				\forall U\in\mathcal{T}\exists \lbrace B_i\rbrace_{i\in J}\subset \mathcal{T}: U=\bigcup_{i\in J}B_i
			\end{equation*}
		\end{defn}
		\begin{bsp}
			Ist $(X,d)$ ein metrischer Raum, so bilden die bzgl. der Metrik offenen Mengen eine Topologie mit den $\varepsilon$-Bällen $\lbrace B_{\varepsilon}(x)\mid x\in X, \varepsilon >0\rbrace$ als Basis.
		\end{bsp}
		\begin{defn}[Zweitabzählbarkeit]
			Ein topologischer Raum $(X,\mathcal{T})$ heißt \emph{zweitabzählbar}, wenn für die Topologie $\mathcal{T}$ eine abzählbare Basis existiert. 
		\end{defn}
		\begin{defn}[Kompaktheit]
			Eine Teilmenge $K\subset X$ heißt \emph{kompakt}, wenn jede offene Überdeckung (das heißt jede Familie offener Mengen $\lbrace U_i\rbrace_{i\in I}$ mit $K\subset \bigcup_{i\in I}U_i$) eine endliche Teilüberdeckung hat (also endlich viele $U_1,\ldots,U_n$ existieren sodass schon $K\subset \bigcup_{i=1}^n U_i$ gilt).
		\end{defn}
		\begin{defn}[Hausdorffraum]
			Ein topologischer Raum $(X,\mathcal{T})$ heißt \emph{hausdorffsch} oder \emph{Hausdorffraum}, falls für je zwei Punkte $x,y\in X, x\neq y$ offene Umgebungen ${U_x,U_y\in\mathcal{T}}$, ${x\in U_x}, {y\in U_y}$ existieren sodass $U_x\cap U_y=\emptyset$. Zwei Punkte können also durch offene Mengen \glqq getrennt\grqq\ werden.
		\end{defn}
		\begin{lemma}
			In einem Hausdorffraum sind kompakte Mengen abgeschlossen.
		\end{lemma}
		\begin{bsp}
			Der euklidische Raum $(\R^n,d)$ ist mit der metrischen Topologie ein topologischer Raum. Er ist hausdorffsch und zweitabzählbar.
		\end{bsp}
		\begin{defn}[Stetige Abbildung]
			Eine Abbildung $f\colon (X,\mathcal{T}_X)\rightarrow (Y,\mathcal{T}_Y)$ zwischen topologischen Räumen heißt \emph{stetig}, wenn Urbilder offener Mengen offen sind:
			\begin{equation*}
				U\in\mathcal{T}_Y \Rightarrow f^{-1}(U)\in\mathcal{T}_X
			\end{equation*}
			Äquivalent dazu ist, dass Urbilder abgeschlossener Mengen abgeschlossen sind (da Komplementbildung mit dem Urbild vertauscht).
		\end{defn}
		Die Topologien werden im Folgenden in der Notation unterdrückt.
		\begin{lemma}
			Die Verkettung stetiger Abbildungen ist stetig.
		\end{lemma}
		\begin{lemma}
			Das Bild einer kompakten Menge unter einer stetigen Abbildung ist kompakt:
			\begin{equation*}
				f\colon X\rightarrow Y \text{ stetig }, K\subset X \text{ kompakt }\Rightarrow f(K)\subset Y \text{ kompakt}
			\end{equation*}
		\end{lemma}
		\begin{defn}[Homöomorphismus]
			Eine stetige Abbildung $f\colon X\rightarrow Y$ heißt \emph{Homöomorphismus}, wenn sie bijektiv und ihre Umkehrabbildung stetig ist.
		\end{defn}
	\section{Mannigfaltigkeiten}
		\begin{defn}
			Ein topologischer Raum $(M,\mathcal{T})$ heißt \emph{topologische Mannigfaltigkeit}, wenn er hausdorffsch, zweitabzählbar und lokal euklidisch ist, das heißt:
			Es existiert eine natürliche Zahl $n\in \mathbb{N}$ (Dimension), sodass für alle Punkte $x\in M$ offene Umgebungen $U\subset M, V\subset \R^n$ mit $x\in U $ und ein Homöomorphismus $ \varphi\colon U\rightarrow V$ existieren.

			Die Dimension der Mannigfaltigkeit ist wohldefiniert (Beachte, dass $n$ unabhängig von der Wahl des Punktes existieren muss).

			Das Tupel $(\varphi,U)$ heißt \emph{Karte} (wobei manchmal die Menge $U$ unterdrückt wird). Eine Familie von Karten, die die Mannigfaltigkeit überdecken, heißt \emph{Atlas} $\mathcal{A}$.
		\end{defn}
		\begin{bsp}\hfill 
			\begin{enumerate}
				\item Der euklidische Raum $\R^n$ ist eine $n$-dimensionale topologische Mannigfaltigkeit, beispielsweise mit dem Atlas $\lbrace (id_{\R^n},\R^n)\rbrace$. Ebenso gilt dies für beliebige offene Teilmengen.
				\item Das kartesische Produkt zweier topologischer Mannigfaltigkeiten (der Dimensionen $n$ und $m$) ist eine topologische Mannigfaltigkeit (der Dimension $n + m$). Die Produkte offener Mengen bilden dabei eine Basis der Topologie des Produktes.
				\item Für topologische Mannigfaltigkeiten gleicher Dimension ist die disjunkte Vereinigung eine topologische Mannigfaltigkeit (\emph{topologische Summe}).
			\end{enumerate}
		\end{bsp}
		\begin{defn}
			Für zwei Karten $\varphi_i\colon U_i\rightarrow V_i, i\in\lbrace 1,2 \rbrace$ heißt die folgende Abbildung \emph{Kartenwechsel}:
			\begin{equation*}
				\varphi_2\circ\varphi_1^{-1}\vert_{\varphi_1(U_1\cap U_2)}\colon \varphi_1(U_1\cap U_2)\rightarrow \varphi_2(U_1\cap U_2)
			\end{equation*}
			Da die Karten Homöomorphismen sind, sind auch alle Kartenwechsel Homöomorphismen.
		\end{defn} 
		\begin{defn}[Differenzierbare Mannigfaltigkeit]\hfill
			\begin{itemize}
				\item Zwei Karten heißen \emph{verträglich}, wenn ihr Kartenwechsel ein (glatter) Diffeomorphismus ist (das heißt, der Kartenwechsel und sein Inverses sind glatt).
				\item Ein Atlas heißt \emph{differenzierbar}, wenn alle seine Karten paarweise verträglich sind.
				\item Ein differenzierbarer Atlas heißt \emph{maximal}, wenn es keine Karte gibt, die mit allen Karten des Atlanten verträglich und nicht in ihm enthalten ist.
				\item Eine \emph{differenzierbare Struktur} auf einer topologischen Mannigfaltigkeit $M$ ist ein maximaler differenzierbarer Atlas $\mathcal{A}$ und das Tupel $(M,\mathcal{A})$ heißt \emph{differenzierbare Mannigfaltigkeit}. Wenn also von einer Karten auf einer differenzierbaren Mannigfaltigkeit die Rede ist, sind immer solche aus der differenzierbaren Struktur gemeint.
			\end{itemize}
		\end{defn}
		\begin{bsp}\hfill 
			\begin{enumerate}
				\item Der euklidische Raum $\R^n$ (und seine offenen Teilmengen) sind $n$-dimensionale differenzierbare Mannigfaltigkeiten, der oben genannte Atlas muss dazu aber erweitert werden! (Übung: Zeige allgemein, dass eine Vervollständigung eines nichtleeren Atlanten eindeutig ist)
				\kommP{Erwähnen, dass jeder dfb. Atlas einen eindeutige dfb. Struktur induziert, mit der er verträglich ist? Übungsaufgabe?}
				\item Reelle, endlich dimensionale Vektorräume sind differenzierbare Mannigfaltigkeiten.
				\item Die obigen Beispiele topologischer Mannigfaltigkeiten gelten auch für differenzierbare Mannigfalltigkeiten, allerdings müssen auch hier Atlanten vervollständigt werden.
				\item Die Sphären ${S^n:=\lbrace x\in\R^{n+1}\mid \|x\|=1\rbrace}$ sind differenzierbare Mannigfaltigkeiten, die sich nicht mit einer einzelnen Karte überdecken lassen.
			\end{enumerate}
		\end{bsp}
	\section{Differenzierbare Abbildungen}
		Seien von nun an $M,N$ differenzierbare Mannigfaltigkeiten.
		\begin{defn}[Differenzierbarkeit]
			Eine Abbildung $f\colon M\rightarrow N$ zwischen differenzierbaren Mannigfaltigkeiten heißt \emph{glatt}, wenn für alle Punkte $p\in M$ Karten $(\varphi,U)$ um  $p$ und $(\psi,V)$ um $f(p)$ existieren, sodass $f(U)\subset V$ und die folgende Abbildung glatt ist:
			\kommP{Evtl. $C^k$ definieren?}
			\begin{equation}
				\psi\circ f \circ \varphi^{-1}\colon \varphi(U)\rightarrow \psi(V)
			\end{equation}
			Diese Definition ist unabhängig von der Wahl der Karte, da Kartenwechsel glatt sind. Äquivalent kann daher auch gefordert werden, dass die obige Abbildung für alle Karten glatt ist.

			Wir schreiben $\sC(M,N)$ für die Menge der glatten Abbildungen.
		\end{defn}
		\begin{nota}
			$\sm(M):=\sC(M,\R)$ ist die Menge der (glatten) Funktionen auf $M$.
		\end{nota}
		\begin{defn}
			Eine Abbildung $f\in\sC(M,N)$ heißt Diffeomorphismus, wenn $f$ bijektiv ist und $f^{-1}\in\sC(N,M)$ gilt.

			Die Menge der Diffeomorphismen $\Diff(M)\subset\sC(M,M)$ bildet eine Gruppe.
		\end{defn}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Der Tangentialraum, das Differential, Untermannigfaltigkeiten}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Der Tangentialraum}
Idee: Was sind \glqq Richtungen\grqq\ auf einer Mannigfaltigkeit?

Anschaulich: Wenn Mf. eingebettet im $\mathbb R^n$, können wir uns eine Tangentialebene vorstellen (Bild: $S^2$ in $\mathbb R^3$). Also: Mögliche Richtungen = Ableitungen von Kurven. Aber abstrakt?

Müssen intrinsisch darüber reden können. Dabei hilft die Beobachtung, dass man Richtungen dazu benutzt, zu beschreiben, wie sich Dinge bei Bewegung in diese Richtung ändern. Also: Richtung = Richtungsableitung! \todo{Ableitung entlang von Kurven im $\mathbb R^n$ als Motivation.} Wir werden deshalb \glqq Richtungen\grqq\ als Ableitungsoperatoren formalisieren.

Idee: Ableitungen erfüllen eine Produktregel und wirken \glqq lokal\grqq.

Sei im Folgenden $M$ eine differenzierbare Mannigfaltigkeit, $\dim M = n$.

\begin{defn}[Funktionskeime]
	Sei $p \in M$. Auf der Menge $X = \{f \in \sC(U) : U \subset M \text{ offene Umgebung von } p\}$ betrachten wir die Äquivalenzrelation $\sim$, die gegeben ist durch
	\[f \sim g \diff \exists \text{ offene Umgebung } V \text{ von } p \text{ mit } f = g \text{ auf } V.\]
	Die Äquivalenzklassen bzgl. dieser Relation heißen glatte \emph{Funktionskeime} an $M$ im Punkt $p$. Zwei um $p$ definierte Funktionen definieren also genau dann denselben Keim, wenn sie in einer Umgebung von $p$ übereinstimmen.

	Den Raum der Funktionskeime an $M$ in $p$ schreiben wir als $\sC_p(M)$. Den Keim zu einer Funktion $f$ schreiben wir als $[f]$. Wenn keine Missverständnisse entstehen können, schreiben wir stattdessen manchmal auch $f$, um uns Notationsaufwand zu ersparen.
\end{defn}

Zu einem Funktionskeim $[f] \in \sC_p(M)$ ist der Funktionswert $[f](p) := f(p)$ wohldefiniert (warum?).

\begin{prop}
	$\sC_p(M)$ ist mit über die Repräsentanten definierter Addition, Skalarmultiplikation und Multiplikation eine $\mathbb R$-Algebra. \bewUeb
\end{prop}

\begin{defn}
	Eine \emph{Derivation} von $\sC_p(M)$ ist eine lineare Abbildung $v\colon \sC_p(M) \to \mathbb R$, die die \glqq Produktregel\grqq\ \[v(fg) = v(f) g(p) + f(p) v(g)\] erfüllt. Den Raum der Derivationen von $\sC_p(M)$ nennen wir den \emph{Tangentialraum} $T_pM$ an $M$ im Punkt $p$; die Elemente von $T_pM$ heißen auch \emph{Tangentialvektoren} in $p$.
\end{defn}

$T_pM$ ist tatsächlich ein Untervektorraum von $(\sC_p(M))^*$ (Übung).

\begin{lemma}[Derivationen verschwinden auf Konstanten]
	Für alle $v \in T_pM$ und $c \in \mathbb R$ ist $v(c) = 0$ (dabei fassen wir $c$ als konstante Funktion bzw. den davon induzierten Funktionskeim auf).
	
	\begin{proof}
		Es ist $v(1) = v(1\cdot 1) = v(1) 1(p) + 1(p) v(1) = 2 v(1)$, also $v(1) = 0$. Da $v$ linear ist, folgt die Behauptung.
	\end{proof}
\end{lemma}

\begin{bsp} \label{bsp:kurve_geschw}
	Sei $I\subset\mathbb R$ offen und $\gamma\colon I \to M$ eine glatte Kurve mit $\gamma(s) = p$ für ein $s \in I$. Wir definieren den Tangentialvektor $\gamma'(s) \in T_pM$ durch \[(\gamma'(s))(f) := (f\circ\gamma)'(s),\] wobei wir auf der rechten Seite die Ableitung der Funktion $f\circ\gamma \colon I \to \mathbb R, I \subset \mathbb R$ gebildet haben.

	$\gamma'(s)$ leitet also die Funktionskeime, auf die es angewendet wird, entlang der Kurve ab; wir können $\gamma'(s)$ also als \glqq Geschwindigkeitsvektor\grqq\ der Kurve auffassen. \kommB{Soll dazu noch eine konkrete Rechnung folgen? Vllt. als Übung? (Also dass man konkret im $\R^n$ nachrechnet, dass da so etwas wie eine Richtung herauskommt (unter Identifikation blabla)}

	$\gamma'(s)$ ist wohldefiniert und tatsächlich eine Derivation: Wenn $[f] = [g]$ gilt, dann stimmen $f$ und $g$ in einer Umgebung von $p$ überein, und damit stimmen $f\circ\gamma$ und $g\circ\gamma$ in einer Umgebung von $s$ überein und haben insbesondere dieselbe Ableitung an der Stelle $s$. Die Linearität von $\gamma'(s)$ folgt aus der Linearität der Ableitung, und die Derivations-Produktregel folgt aus der Produktregel für Ableitungen.
\end{bsp}

Später werden wir sehen, dass sich tatsächlich \emph{jeder} Tangentialvektor als Ableitung einer Kurve schreiben lässt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Das Differential}

Mithilfe des Tangentialraumbegriffs können wir nun nicht nur entscheiden, ob Abbildungen differenzierbar sind, sondern auch tatsächlich eine Art Ableitungsbegriff definieren:
\begin{defn}
	Seien $M,N$ differenzierbare Mannigfaltigkeiten und $f\colon M \to N$ eine glatte Abbildung. Das \emph{Differential} von $f$ im Punkt $p\in M$ ist die lineare Abbildung
	\[\left.\DD f\right|_p \colon T_pM \to T_{f(p)}N\]
	definiert durch
	\[\left(\left.\DD f\right|_p(v)\right)(\alpha) = v (\alpha\circ f)\]
	für $v\in T_pM, \alpha \in \sC_{f(p)}(N)$.
\end{defn}
\begin{prop}
	$\left.\DD f\right|_p(v)$ ist tatsächlich wohldefiniert und eine Derivation von $\sC_{f(p)}(N)$, und $\left.\DD f\right|_p$ ist linear. \bewUeb
\end{prop}

\begin{satz}[Kettenregel]
	Seien $f\colon M \to N, g\colon N \to L$ glatte Abbildungen zwischen differenzierbaren Mannigfaltigkeiten, und $p \in M$. Dann gilt \[\left.\DD(g\circ f)\right|_p = \left.\DD g\right|_{f(p)} \circ \left.\DD f\right|_p.\]

	\begin{proof}
		Sei $v \in T_pM$. Für jedes $\alpha \in \sC_{g(f(p))}(L)$ ist
		\begin{align*}
			\left(\left.\DD(g\circ f)\right|_p(v)\right)(\alpha) &= v(\alpha\circ (g \circ f))\\
			&= v((\alpha\circ g) \circ f)\\
			&= \left(\left.\DD f\right|_p(v)\right) (\alpha \circ g)\\
			&= \left(\left.\DD g\right|_{f(p)} \left(\left.\DD f\right|_p(v)\right)\right) (\alpha),
		\end{align*}
		also gilt $\left.\DD(g\circ f)\right|_p(v) = \left.\DD g\right|_{f(p)}\left(\left.\DD f\right|_p(v)\right)$.
	\end{proof}
\end{satz}

\begin{lemma} \label{lemma:differential_diffeo}
	\begin{enumerate}[label=(\alph*)]
		\item $\left.\DD(\id_M)\right|_p = \id_{T_pM}$
		\item Ist $f\colon M \to N$ ein Diffeomorphismus, so ist $\left.\DD f\right|_p$ für jedes $p\in M$ ein Isomorphismus, und es gilt $\left.\DD f^{-1}\right|_{f(p)} = \left(\left.\DD f\right|_p\right)^{-1}$.
	\end{enumerate}
	\bewUeb
\end{lemma}

\begin{prop}
	Sei $M$ eine differenzierbare Mannigfaltigkeit und $U\subset M$ eine offene Teilmenge. Für jedes $p\in U$ ist $T_pU$ kanonisch isomorph zu $T_pM$ vermöge $\left.\DD i\right|_p$, wobei $i\colon U \to M, i(q) := q$ die Inklusionsabbildung ist.

	\begin{proof}
		Sei $p \in U$. $\left.\DD i\right|_p$ ist definiert über $\left(\left.\DD i\right|_p(v)\right)(\alpha) = v(\alpha\circ i)$ für $v \in T_pU$ und $\alpha \in \sC_p(M)$; d.\,h. $\left.\DD i\right|_p(v)$ ist einfach $v$, nur aufgefasst als Derivation, die Funktionskeime an $M$ ableitet, indem man diese als Funktionskeime an $U$ auffasst. Da Funktionskeime an $U$ in $p$ und Funktionskeime an $M$ in $p$ aber einander entsprechen, ist damit klar, dass $\left.\DD i\right|_p$ ein Isomorphismus ist.

		Etwas genauer: Jeder Funktionskeim $\tilde\alpha \in \sC_p(U)$ kann auch als Keim $\alpha \in \sC_p(M)$ aufgefasst werden, und umgekehrt: Jede offene Umgebung von $p$ in $U$ ist auch offen in $M$, und jede offene Umgebung von $p$ in $M$ enthält eine offene Umgebung von $p$ in $U$. Da bei der Definition von Funktionskeimen um $p$ Funktionen äquivalent sind, wenn sie auf einer offenen Umgebung von $p$ übereinstimmen, spielt es also keine Rolle, ob wir in $U$ oder in $M$ sind (\glqq es wird eh alles äquivalent gemacht\grqq)\footnote{
			Als Element von $\sC_p(M)$ besteht der Keim / die Äquivalenzklasse potentiell aus mehr Funktionen, da auch noch Funktionen dazukommen, die auf \glqq größeren\grqq\ Umgebungen von $p$ definiert sind.
		}.

		Diese Abbildung $\sC_p(M) \ni \alpha \mapsto \tilde\alpha \in \sC_p(U)$ ist also für $[f]_{p,M} \in \sC_p(M)$, $f$ definiert auf $V$, gegeben durch $[f]_{p,M} \mapsto \left[\left.f\right|_{U\cap V}\right]_{p,U} \in \sC_p(U)$, was man auch schreiben kann als $[f]_{p,M} \mapsto \left[\left.f\circ i\right|_{U\cap V}\right]_{p,U}$. D.\,h. das oben beschriebene Auffassen von $\alpha$ als Keim auf der kleineren Mannigfaltigkeit $U$ ist die Abbildung $\sC_p(M) \ni \alpha \mapsto \alpha\circ i \in \sC_p(U)$. Wie oben beschrieben lässt sich das umkehren, ist also ein Isomorphismus. Damit ist aber auch $\left.\DD i\right|_p$ ein Isomorphismus, denn es ist definiert als $\left(\left.\DD i\right|_p(v)\right)(\alpha) = v(\alpha\circ i)$.
	\end{proof}
\end{prop}

Da $\left.\DD i\right|_p(v)$ einfach dieselbe Derivation wie $v$ ist (sie unterscheiden sich nur darin, ob man die Keime, auf die sie wirkt, als Keime an $M$ oder an $U$ betrachtet), werden wir im Folgenden $T_pU$ und $T_pM$ (meistens) miteinander identifizieren.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Der Tangentialraum eines Vektorraums}

Betrachten wir einen endlich-dimensionalen Vektorraum $V$, so sagt uns die Intuition, dass die Richtungen, in die wir ableiten können, einfach die Richtungen des Vektorraums sein sollten. Wir erwarten also einen kanonischen Isomorphismus $T_pV \cong V$ für alle $p \in V$. Sei im Folgenden $V$ ein endlich-dimensionaler Vektorraum und $p \in V$ ein fester Punkt.
\begin{defn}
	Für $v \in V$ definieren wir den Tangentialvektor $\left.\partial_v\right|_p \in T_pV$ durch
	\[\left.\partial_v\right|_p(f) := (\partial_v f)(p) = \left.\frac{\D f(p + h v)}{\D h}\right|_{h=0} = \lim_{h\to 0} \frac{f(p + h v) - f(p)}{h}.\]
\end{defn}
$\left.\partial_v\right|_p$ ist also einfach die Richtungsableitung in Richtung von $v$ am Punkt $p$.
\begin{prop}
	$\left.\partial_v\right|_p$ ist tatsächlich eine Derivation von $\sC_p(V)$.
	
	\begin{proof}
		$\left.\partial_v\right|_p$ ist wohldefiniert, denn wenn $[f] = [g]$ gilt, dann stimmen $f$ und $g$ in einer Umgebung von $p$ überein und haben insbesondere dieselben Ableitungen an der Stelle $p$. Dass Richtungsableitungen linear sind und die Produktregel erfüllen, ist bekannt\footnote{Oder folgt schnell aus den entsprechenden Eigenschaften für Ableitungen von Funktionen $\mathbb R \to \mathbb R$.}.
	\end{proof}
\end{prop}

\begin{satz} \label{satz:tangt_vr}
	Die Abbildung \[V \to T_pV, v \mapsto \left.\partial_v\right|_p\] ist ein linearer Isomorphismus.
	
	\begin{proof}\let\qed\relax
		Linearität ist einfach zu zeigen (Übung). Um Surjektivität und Injektivität zu zeigen, fixieren wir eine Basis $\{b_1,\dots,b_n\}$ von $V$. Sei $\{\theta^1, \dots, \theta^n\}$ die dazu duale Basis von $V^*$, also für $i = 1, \dots, n$ jeweils $\theta^i\colon V \to \mathbb R$ die lineare Abbildung definiert durch $\theta^i(b_j) = \delta^i_j$ und lineare Fortsetzung.

		Für beliebiges $v = \sum_{i=1}^n v^i b_i \in V$ ist $\left.\partial_v\right|_p(\theta^i) = \left.\frac{\D\theta^i(p + h v)}{\D h}\right|_{h=0} = \left.\frac{\D(\theta^i(p) + h v^i)}{\D h}\right|_{h=0} = v^i$ für alle $i$. Falls $\left.\partial_v\right|_p = 0$ gilt, ist also $v^i = \left.\partial_v\right|_p(\theta^i) = 0(\theta^i) = 0$, also $v=0$. Das zeigt, dass der Kern der betrachteten Abbildung nur die 0 enthält, also deren Injektivität. Um die Surjektivität zu zeigen, brauchen wir einen kleinen Trick.
	\end{proof}
\end{satz}

\begin{lemma}[Hadamard-Lemma] \label{lemma:Hadamard}
	Seien $U \subset \mathbb R^n$ eine offene Menge, die sternförmig um $x_0$ ist, und $f \in \sC(U)$. Dann gibt es glatte Funktionen $f_i \in \sC(U), i = 1,\dots,n$, sodass \[f(x) = f(x_0) + \sum_{i=1}^n f_i(x) (x^i - x_0^i).\]
	
	\begin{proof}
		Für $x \in U$ setze $y := x - x_0$. Dann ist
		\begin{align*}
		f(x) - f(x_0) &= f(x_0 + 1\cdot y) - f(x_0 + 0\cdot y)\\
		&= \int_0^1 \left(\frac{\D}{\D t} f(x_0 + ty)\right) \D t\\
		\text{(Kettenregel)} \quad &= \int_0^1 \sum_{i=1}^n (\partial_i f)(x_0 + ty) y^i \D t\\
		&= \sum_{i=1}^n \left(\int_0^1 (\partial_i f)(x_0 + tx - tx_0) \D t\right) (x^i - x_0^i).
		\end{align*}
		Mit \[f_i(x) := \int_0^1 (\partial_i f)(x_0 + tx - tx_0) \D t\] folgt also die Behauptung (die $f_i$ sind glatt wegen Kettenregel und Sätzen über das Differenzieren unter dem Integral).
	\end{proof}
\end{lemma}

\begin{kor}[Hadamard-Lemma auf Vektorräumen]
	Sei $\theta = (\theta^1, \dots, \theta^n) \colon V \to \mathbb R^n$ ein linearer Isomorphismus und sei $\alpha \in \sC_p(V)$. Dann gibt es $\alpha_i \in \sC_p(V), i = 1,\dots, n$ mit \[\alpha = \alpha(p) + \sum_{i=1}^n \alpha_i \cdot (\theta^i - \theta^i(p)).\]
	
	\begin{proof}
		Das ist einfach das Hadamard-Lemma \ref{lemma:Hadamard} angewendet auf unseren Vektorraum $V$, der über $\theta$ mit $\mathbb R^n$ identifiziert wurde.
	\end{proof}
\end{kor}

\begin{proof}[Zurück zum Beweis von Satz \ref{satz:tangt_vr}]
	Mit dem Hadamard-Lemma können wir jetzt auch zeigen, dass die Abbildung $v \mapsto \left.\partial_v\right|_p$ surjektiv ist. Seien $w \in T_pV$ und $\alpha \in \sC_p(V)$ beliebig, und seien $\alpha_i \in \sC_p(V)$ zu $\alpha$ mit dem Hadamard-Lemma gewählt. Dann ist
	\begin{align}\begin{split} \label{eq:pf_tangt_vr}
		w(\alpha) &= w\left(\alpha(p) + \sum_{i=1}^n \alpha_i \cdot (\theta^i - \theta^i(p))\right)\\
		\text{(Linearität, $w(\text{const.}) = 0$)} \quad &= \sum_{i=1}^n w(\alpha_i \cdot (\theta^i - \theta^i(p)))\\
		&= \sum_{i=1}^n \left( w(\alpha_i) \cdot (\theta^i(p) - \theta^i(p)) + \alpha_i(p) \cdot w(\theta^i) \right)\\
		&= \sum_{i=1}^n \alpha_i(p) \cdot w(\theta^i).
	\end{split}\end{align}
	Insbesondere gilt damit auch $\left.\partial_v\right|_p (\alpha) = \sum_{j=1}^n \alpha_i(p) \cdot \left.\partial_v\right|_p (\theta^i) = \sum_{j=1}^n \alpha_i(p) \cdot v^i$ für beliebige Vektoren $v = \sum_{i=1}^n v^i b_i$. Wenn wir also $v := \sum_{i=1}^n w(\theta^i) b_i$ setzen, ist $w(\alpha) = \left.\partial_v\right|_p (\alpha)$.

	Da $\alpha$ beliebig war, gilt also $w = \left.\partial_v\right|_p$. Wir können also jedes $w \in T_pV$ als Richtungsableitung in Richtung eines Vektors $v\in V$ schreiben.
\end{proof}

Der Tangentialraum $T_pV$ an einen Vektorraum $V$ ist also in kanonischer Weise zu $V$ selbst isomorph; ein Vektor $v \in V$ wird dabei mit der Richtungsableitung $\left.\partial_v\right|_p$ identifiziert.

\begin{kor}
	Auf dem $\mathbb R^n$ bilden die partiellen Ableitungsoperatoren $\left.\partial_1\right|_p, \dots, \left.\partial_n\right|_p$ eine Basis des Tangentialraums $T_p\mathbb R^n$.

	\begin{proof}
		$\left.\partial_i\right|_p$ ist die Richtungsableitung in Richtung des Standardbasisvektors $\e_i$.
	\end{proof}
\end{kor}

\begin{kor} \label{kor:entw_tangt_Rn}
	Die Entwicklung eines Tangentialvektors $w \in T_p\mathbb R^n$ in dieser Basis ist
	\[w = \sum_{i=1}^n w(\pr^i) \left.\partial_i\right|_p,\]
	wobei $\pr^i\colon \mathbb R^n \to R, \pr^j(a) = a^j$ die Projektion auf die $i$-te Komponente ist.

	\begin{proof}
		Das ergibt sich direkt aus dem Beweis von Satz \ref{satz:tangt_vr}, da die Projektionen $\pr^i$ die zu $\e_i$ duale Basis von $(\mathbb R^n)^*$ bilden.
	\end{proof}
\end{kor}

\begin{bsp}
	Ist $U\subset\mathbb R^n$ offen und $p\in U$, so bilden die partiellen Ableitungsableitungen $\left.\partial_1\right|_p, \dots, \left.\partial_n\right|_p$ eine Basis von $T_pU$ (denn es ist ja $T_pU = T_p\mathbb R^n$).
\end{bsp}

\begin{satz}[Differential von linearen Abbildungen]
	Sei $L\colon V \to W$ eine lineare Abbildung. Bzgl. der Identifikationen $T_pV \equiv V, T_{L(p)}W \equiv W$ ist $\left.\DD L\right|_p = L$.

	\begin{center}
		\begin{tikzpicture}
		\matrix(m)[matrix of math nodes,row sep=4em,column sep=4em,minimum width=2em]{T_pV & T_{L(p)}W \\
			V&W \\};
		\path[-stealth]
		(m-1-1)	edge node [above]{$\left.\DD L\right|_p$} (m-1-2)
		(m-2-1) edge node [left]{$v \mapsto \left.\partial_v\right|_p$} (m-1-1)
		(m-2-2) edge node [right]{$w \mapsto \left.\partial_w\right|_{L(p)}$} (m-1-2)
		(m-2-1) edge node [above]{$L$} (m-2-2)
		;
		\end{tikzpicture}
	\end{center}

	\begin{proof}
		Für $v\in V$ ist
		\begin{align*}
			\left(\left.\DD L\right|_p \left( \left.\partial_v\right|_p \right)\right) (f) &= \left.\partial_v\right|_p (f \circ L)\\
			&= \left.\frac{\D f(L(p + h v))}{\D h}\right|_{h=0}\\
			&= \left.\frac{\D f(L(p) + h L(v))}{\D h}\right|_{h=0}\\
			&= \left.\partial_{L(v)}\right|_{L(p)} (f)
		\end{align*}
		für beliebige $f$, also $\left.\DD L\right|_p \left( \left.\partial_v\right|_p \right) = \left.\partial_{L(v)}\right|_{L(p)}$.
		Das mussten wir aber zeigen.
	\end{proof}
\end{satz}

\begin{bsp}
	Sei $I \subset \mathbb R$ eine offene Menge, $s \in I$ und $\left.\partial_1\right|_s$ der kanonische Ableitungsoperator, der eine Basis von $T_s I$ bildet.

	Ist $M$ eine differenzierbare Mannigfaltigkeit und $\gamma\colon I \to M$ eine glatte Kurve, so können wir das Differential $\left.\DD \gamma\right|_s \colon T_sI \to T_{\gamma(s)} M$ betrachten. Dieses bildet den Basisvektor $\left.\partial_1\right|_s$ ab auf die Derivation $\left.\DD \gamma\right|_s(\left.\partial_1\right|_s)$, die wirkt als $\left(\left.\DD \gamma\right|_s(\left.\partial_1\right|_s)\right)(f) = \left.\partial_1\right|_s (f\circ\gamma) = \left.\frac{\D(f\circ\gamma)(s + h)}{\D h}\right|_{h=0} = (f\circ\gamma)'(s)$. Das ist aber genau die Wirkung des in Beispiel \ref{bsp:kurve_geschw} definierten \glqq Geschwindigkeitsvektors\grqq\ $\gamma'(s) \in T_{\gamma(s)} M$, also gilt $\left.\DD \gamma\right|_s(\left.\partial_1\right|_s) = \gamma'(s)$.

	Der \glqq Geschwindigkeitsvektor\grqq\ $\gamma'(s)$ ist also tatsächlich in einem formalen Sinne die Ableitung der Kurve $\gamma$ an der Stelle $s$, nämlich das Differential von $\gamma$ an dieser Stelle angewendet auf den kanonischen Basisvektor von $T_sI$.
\end{bsp}

\begin{lemma}[Differential von glatten Funktionen als Anwendung der Derivation]
	Für $f\in\sC(M)$ und $v \in T_pM$ ist $\left.\DD f\right|_p(v) = v(f)$ unter der kanonischen Identifikation $T_{f(p)}\mathbb R \equiv \mathbb R$.

	\begin{proof}
		Nach Korollar \ref{kor:entw_tangt_Rn} ist $\left.\DD f\right|_p(v) = \Big(\DD f\big|_p(v)\Big)(\id) \cdot \left.\partial_1\right|_{f(p)} \in T_{f(p)}\mathbb R$. Da nach Definition $\Big(\DD f\big|_p(v)\Big)(\id) = v(\id \circ f) = v(f)$ gilt und $\left.\partial_1\right|_{f(p)}$ unter $T_{f(p)}\mathbb R \equiv \mathbb R$ mit $1$ identifiziert wird, folgt die Behauptung.
	\end{proof}
\end{lemma}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Koordinatenvektoren}

Haben wir auf einer Mannigfaltigkeit $M$ eine Karte $(x,U)$ gegeben, dann ermöglicht sie uns, $U$ mit einer offenen Teilmenge des $\mathbb R^n$ zu identifizieren. Das gilt auch für die Tangentialräume:
\begin{defn}
	Sei $M$ eine differenzierbare Mannigfaltigkeit, $p\in M$ und $(x,U)$ eine Karte um $p$. Wir schreiben $V = x(U) \subset \mathbb R^n$. Als Abbildung $x\colon U \to V$ ist $x$ ein Diffeomorphismus (Übung!). Nach Lemma \ref{lemma:differential_diffeo} ist dann also
	\[\left.\DD x\right|_p \colon T_pM \to T_{x(p)} \mathbb R^n\]
	ein Isomorphismus, wobei wir die Identifikationen $T_pM = T_pU$, $T_{x(p)}\mathbb R^n = T_{x(p)} x(U)$ benutzt haben. Diesen benutzen wir, um aus der kanonischen Basis $\{\left.\partial_i\right|_{x(p)}\}$ von $T_{x(p)}\mathbb R^n$ eine Basis von $T_pM$ zu erhalten: Für $i = 1,\dots, n$ definieren wir
	\[\left.\frac{\partial}{\partial x^i}\right|_p := \left(\left.\DD x\right|_p\right)^{-1} \left(\left.\partial_i\right|_{x(p)}\right) = \left.\DD x^{-1}\right|_{x(p)} \left(\left.\partial_i\right|_{x(p)}\right)\]
	Die $\left.\frac{\partial}{\partial x^i}\right|_p$ heißen die von $x$ \emph{induzierten Koordinatenvektoren} in $p$, zusammen bilden sie die von $x$ induzierte \emph{Koordinatenbasis} von $T_pM$.
\end{defn}
Die Koordinatenvektoren wirken durch
\[\left.\frac{\partial}{\partial x^i}\right|_p(f) = \left.\partial_i\right|_{x(p)} (f \circ x^{-1}) = \left(\partial_i (f\circ x^{-1})\right) (x(p)).\]
$\left.\frac{\partial}{\partial x^i}\right|_p$ stellt also einen Funktionskeim in der Karte $x$ dar und bildet die $i$-te partielle Ableitung dieser Kartendarstellung.

\begin{bem}
	Wenn wir in Koordinaten rechnen wollen, schreiben wir Karten meist als $x = (x^1, \dots, x^n)$ o.\,ä. statt als $\varphi$ o.\,ä., da das zur historisch etablierten Notation von Koordinatenvektoren passt. Die Funktionen $x^i$ nennt man dann auch \emph{Koordinatenfunktionen}, die $x^i(p)$ sind die \emph{Koordinaten} von $p$.

	Aufpassen muss man dann allerdings manchmal, wenn man Punkte im $\mathbb R^n$ auch als $x$ schreibt (deshalb haben wir das oben auch eher vermieden).
\end{bem}

\begin{bsp}
	Für eine Karte $(x,U)$ um $p$ sind die Komponenten $x^i, i = 1,\dots, n$ reellwertige glatte Funktionen auf $U$, können also als Funktionskeime in $p$ aufgefasst werden. Wendet man darauf die Koordinatenvektoren an, so erhält man
	\begin{align*}
		\left.\frac{\partial}{\partial x^i}\right|_p (x^j) &= \left(\partial_i \left(x^j\circ x^{-1}\right)\right) (x(p))\\
		&= \underbrace{\left(\partial_i \pr^j\right)}_{= \delta^j_i} (x(p)) = \delta^j_i,
	\end{align*}
	wobei $\pr^j\colon \mathbb R^n \to R, \pr^j(a) = a^j$ die Projektion auf die $j$-te Komponente ist.
\end{bsp}

\begin{lemma}[Koordinatendarstellung von Tangentialvektoren]
	Sei $M$ eine differenzierbare Mannigfaltigkeit, $p \in M$, $v \in T_pM$ und $x$ eine Karte um $p$. Die Darstellung von $v$ in der von $x$ induzierten Koordinatenbasis ist
	\[v = \sum_{i=1}^n v^i \left.\frac{\partial}{\partial x^i}\right|_p\]
	mit
	\[v^i = v(x^i).\]

	\begin{proof}
		Nach Korollar \ref{kor:entw_tangt_Rn} ist $\left.\DD x\right|_p(v) = \sum_{i=1}^n \Big(\DD x\big|_p(v)\Big) (\pr^i) \left.\partial_i\right|_{x(p)}$. Da nach Definition $\Big(\DD x\big|_p(v)\Big) (\pr^i) = v(\pr^i \circ x) = v(x^i)$ ist, haben wir also $\left.\DD x\right|_p(v) = \sum_{i=1}^n v(x^i) \left.\partial_i\right|_{x(p)}$.
		Anwenden von $\left(\left.\DD x\right|_p\right)^{-1}$ auf beiden Seiten liefert die Behauptung.
	\end{proof}
\end{lemma}

\begin{lemma}[Differential in Kartendarstellung] \label{lemma:differential_koord}
	Sei $f\colon M \to N$ eine glatte Abbildung zwischen differenzierbaren Mannigfaltigkeiten. Sei $p\in M$, $x$ eine Karte von $M$ um $p$ und $y$ eine Karte von $N$ um $f(p)$. Dann ist die Darstellungsmatrix des Differentials $\left.\DD f\right|_p$ bzgl. der Koordinatenbasen $\left.\frac{\partial}{\partial x^i}\right|_p$ von $T_pM$ und $\left.\frac{\partial}{\partial y^i}\right|_{f(p)}$ von $T_{f(p)}N$ die Jacobi-Matrix der Kartendarstellung $y \circ f \circ x^{-1}$ von $f$ an der Stelle $x(p)$, also die Matrix
	\[\mathrm{J}(y\circ f\circ x^{-1})|_{x(p)} = \left[\left(\partial_j(y\circ f\circ x^{-1})^i\right) (x(p)) \right]_{ij}.\]
	\bewUeb
\end{lemma}

\begin{defn}
	Sei $M$ eine differenzierbare Mannigfaltigkeit und $(x,U)$ eine Karte. Für $f \in \sC(U)$ definieren wir die Funktionen $\frac{\partial f}{\partial x^i} \in \sC(U)$ durch
	\[\frac{\partial f}{\partial x^i}(p) := \left.\frac{\partial}{\partial x^i}\right|_p(f).\]
	Manchmal nennen wir diese Funktionen die \emph{partiellen Ableitungen} von $f$ bzgl. der Karte $x$, wobei das natürlich \emph{abuse of language} ist.
\end{defn}

Mit dieser Notation ist die Darstellungsmatrix des Differentials aus Lemma \ref{lemma:differential_koord} also
\[\left[\frac{\partial(y^i \circ f)}{\partial x^j}(p)\right]_{ij}.\]

\begin{lemma}[Transformationsformel für Tangentialvektoren]
	Sei $M$ eine differenzierbare Mannigfaltigkeit, $p\in M$ und seien $x, y$ zwei Karten um $p$. Für die Koordinatenvektoren gilt
	\[\left.\frac{\partial}{\partial y^i}\right|_p = \sum_{j=1}^n \frac{\partial x^j}{\partial y^i}(p) \left.\frac{\partial}{\partial x^j}\right|_p.\]
	Die Basiswechselmatrix ist also die Jacobi-Matrix des inversen Kartenwechsels $x \circ y^{-1}$ (an der Stelle $y(p)$).

	Für einen Tangentialvektor $v = \sum_{i=1}^n v^i \left.\frac{\partial}{\partial x^i}\right|_p = \sum_{i=1}^n \tilde v^i \left.\frac{\partial}{\partial y^i}\right|_p$ gilt dementsprechend
	\[\tilde v^j = \sum_{i=1}^n \frac{\partial y^j}{\partial x^i}(p) v^i.\]

	\bewUeb
\end{lemma}

\todo{Summenkonvention einführen.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ableitungen von Kurven}
\begin{bsp}
	Für eine offene Menge $I\subset\mathbb R$ schreibt man die kanonische Karte $\id_I\colon I \to I$ oft als $t$ und den davon induzierten Koordinatenvektor dann als $\left.\frac{\D}{\D t}\right|_s \in T_sI$. Das ist natürlich einfach der normale Ableitungsoperator an der Stelle $s$, den wir oben schon als $\left.\partial_1\right|_s$ geschrieben haben. Für eine glatte Kurve $\gamma\colon I \to M$ ist also
	\[\gamma'(s) = \left.\DD\gamma\right|_s \left(\left.\frac{\D}{\D t}\right|_s\right).\]

	Statt $\gamma'(s)$ schreiben wir für die Ableitung einer Kurve an der Stelle $s$ in Zukunft auch
	\[\gamma'(s) = \left.\frac{\D}{\D t}\gamma(t)\right|_{t = s}.\]

	Man kann sich überlegen, dass
	\[\gamma'(s) = \left.\frac{\D}{\D t}\gamma(s + t)\right|_{t = 0}\]
	gilt (Übung!).
\end{bsp}
\todo{Ausarbeiten! Zeigen: Jeder Tangentialvektor ist Ableitung einer Kurve. Koordinatenvektoren sind Ableitungen von Koordinatenlinien.}

\section{Untermannigfaltigkeiten}
\kommP{Weglassen? Brauchen wir nicht später, und wir haben eh zu wenig Zeit, und das Kapitel ist eh zu voll ...}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Vektorbündel}
	\section{Faserbündel}
		\begin{defn}[Faserbündel]
			Ein \emph{Faserbündel} $(P,M,\pi ,F)$ ist ein Tupel aus drei Mannigfaltigkeiten (dem \emph{Totalraum} $P$, der \emph{Basis} $M$ und der \emph{typischen Faser} $F$) zusammen mit einer surjektiven \emph{Projektion} $\pi\colon P\rightarrow M$, die die folgenden Eigenschaften erfüllt:

				Für alle Punkte $x\in M$ existieren eine offene Umgebung $x\in U\subset M$ und ein Diffeomorphismus $\phi\colon \pi^{-1}(U)\rightarrow U\times F$, sodass das folgende Diagramm kommutiert, also $\pi\vert_{\pi^{-1}(U)}=\pr_1\circ\phi$ (wobei $\pr_1$ die Projektion auf den ersten Faktor bezeichnet):
			\begin{center}
			\begin{tikzpicture}
				\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{\pi^{-1}(U) & U\times F \\
     U& \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$\phi$} (m-1-2)
  							edge node [left]{$\pi$} (m-2-1)
  					(m-1-2) edge node [below]{$\quad\pr_1$} (m-2-1)
  					;
			\end{tikzpicture}
			\end{center}
			Eine solche Abbildung $\phi$ heißt \emph{lokale Trivialisierung}. Aufgrund der Existenz lokaler Trivialisierungen ist das Urbild jedes Punktes $x\in M$ unter der Projektion (\emph{Faser} von $x$ genannt) $P_x:=\pi^{-1}(\lbrace x\rbrace )$ diffeomorph zur typischen Faser: $P_x\cong F \; \forall x\in M$.

			Eine Familie lokaler Trivialisierungen, die $P$ überdecken, heißt \emph{Bündelatlas}.
		\end{defn}
		\begin{nota}
			Man sagt auch \glqq Faserbündel über $M$\grqq und schreibt dafür einfach $(P,\pi)$.
		\end{nota}
		Sei von nun an $(P,M,\pi ,F)$ ein Faserbündel.
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Das triviale Bündel mit typischer Faser $F$ und Basis $M$ ist das kartesische Produkt $M\times F$ (genauer gesagt das Bündel $(M\times F,\pr_1))$.
				\item Für eine offene Menge $U\subset M$ und $P\vert_U:=\pi^{-1}(U)$ ist $(P\vert_U,U,\pi\vert_{P_U},F)$ ein Faserbündel.
			\end{enumerate}
		\end{bsp}
		\begin{defn}[Schnitt]
			Eine Abbildung $\sigma\colon M\rightarrow P$ heißt (globaler) \emph{Schnitt}, wenn $\pi\circ\sigma=\id_M$, also $\sigma(x)\in P_x\, \forall x\in M$. Analog heißt für eine offene Menge $U\subset M$ eine Abbildung $\sigma\colon U\rightarrow P\vert_U$ \emph{lokaler Schnitt}, wenn $\pi\circ\sigma=\id_U$.

			Die Menge aller globalen Schnitte wird mit $\Gamma(P)$ bezeichnet, die der lokalen Schnitte mit $\Gamma(P\vert_U)$.
		\end{defn}
	\section{Vektorbündel}
		\begin{defn}[Vektorbündel]
				Ein Faserbündel $(E,M,\pi,\R^n)$ heißt \emph{Vektorbündel} vom \emph{Rang} $n$, wenn $E_x$ für alle Punkte $x\in M$ ein $n$-dimensionaler Vektorraum ist. Weiter soll es einen Bündelatlas aus lokalen Trivialisierungen ${\phi\colon \pi^{-1}(U)\rightarrow U\times \R^n}$ geben, sodass die folgende Abbildung für jeden Punkt $x\in U$ ein Vektorraumisomorphismus ist:
				\begin{equation*}
					E_x\rightarrow \R^n,\; p\mapsto \pr_2(\phi(p))
				\end{equation*}
			Daraus folgt, dass die Abbildung ${\R^n\rightarrow E_x,\; v\mapsto \phi^{-1}(x,v)}$ ebenfalls ein Vektorraumisomorphismus ist.
		\end{defn}
		Analog zu Kartenwechseln lassen sich auch \emph{Trivialisierungswechsel} definieren:
		\begin{defn}
			Sei $(E,M,\pi,\R^n)$ ein Vektorbündel, $U,V\subset M$ mit $U\cap V\neq\emptyset$ und Trivialisierungen ${\phi_U\colon \pi^{-1}(U)\rightarrow U\times \R^n}, {\phi_V\colon \pi^{-1}(U)\rightarrow U\times \R^n}$.

			Die folgende Abbildung heißt \emph{Trivialisierungswechsel}:
			\begin{equation*}
				\phi_V\circ\phi_U^{-1}\colon (U\cap V)\times \R^n\rightarrow (U\cap V)\times \R^n, (q,v)\mapsto (q,\tau(q)v)
			\end{equation*}
			wobei die Einschränkung unterdrückt wurde. Die Abbildung $\tau\colon U\cap V\rightarrow \GL(n,\R)$ ist glatt und wird als \emph{Übergangsfunktion} bezeichnet.
		\end{defn}
		\begin{defn}[Vektorbündelhomomorphismen]\hfill\\
			Seien $(E_a,M_a,\pi_a,\R^{n_a}),(E_b,M_b,\pi_b,\R^{n_b})$ Vektorbündel.
			
			Ein Tupel $(F,f)$ mit $F\colon E_a\rightarrow E_b$ und $f\colon M_a\rightarrow M_b$ heißt \emph{Vektorbündelhomomorphismus}, wenn das folgende Diagramm kommutiert:
			\begin{center}
				\begin{tikzpicture}
					\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{E_a & E_b \\
     M_a&M_b \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$F$} (m-1-2)
  							edge node [left]{$\pi_a$} (m-2-1)
  					(m-1-2) edge node [right]{$\pi_b$} (m-2-2)
  					(m-2-1) edge node [above]{$f$} (m-2-2)
  					;
				\end{tikzpicture}
			\end{center}
			also $\pi_b\circ F=f\circ\pi_a$.
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Das triviale Bündel $M\times \R^n$ ist ein Vektorbündel vom Rang $n$.
				\item Das Tangentialbündel $TM:=\bigcup_{x\in M}T_xM$ ist ein Vektorbündel vom Rang $n:=\dim M$. Beachte jedoch, dass im Allgemeinen $TM\ncong M\times \R^n$ (es existiert also nicht unbedingt ein Vektorbündelisomorphismus zwischen dem Tangential- und dem trivialen Bündel). Im Fall $TM\cong M\times \R^n$ heißt die Mannigfaltigkeit parallelisierbar.
			\end{enumerate}
		\end{bsp}
		\begin{defn}[Rahmen]
			Ein \emph{lokaler Rahmen} über $U$ ist ein Tupel lokaler Schnitte $(\sigma_1,\ldots,\sigma_2)\in\Gamma(P\vert_U)$, das für alle Punkte $x\in U$ eine Basis von $E_x$ bildet. 
			
			Beachte: Ist $(\phi,U)$ eine Trivialisierung und $(e_1,\ldots,e_n)$ die Standardbasis von $\R^n$, dann ist mit $\sigma_i(x):=\phi^{-1}(x,e_i)$ das Tupel $(\sigma_1,\ldots,\sigma_n)$ ein lokaler Rahmen über $U$.
			
			Natürlicherweise ist ein \emph{globaler Rahmen} ein lokaler Rahmen über $M$.
		\end{defn}
		\begin{satz}
			Ein Vektorbündel besitzt genau dann einen globalen Rahmen, wenn es trivial ist (das heißt isomorph zum trivialen Bündel).
		\end{satz}
		Später brauchen wir noch folgendes Ergebnis:
		\begin{kor}\label{kor:Vektorbündel_über_Intervallen}
			Vektorbündel über offenen Intervallen sind trivial.
		\end{kor}
	\section{Konstruktionen von Vektorbündeln}
		Seien $(E_a,M,\pi_a,\R^{n_a}),(E_b,M,\pi_b,\R^{n_b})$ Vektorbündel.\\
		\begin{defn}
			Das zu $(E,M,\pi,\R^{n})$ \emph{duale Bündel} $(E^*,M,\pi^{\prime},(\R^n)^*)$ ist gegeben durch
			\begin{align*}
				E^*&:=\bigcup_{x\in M}(E_{x})^*\\
				\pi^{\prime}&\colon E^*\rightarrow M\\
				(\pi^{\prime})^{-1}(x)&=E^*_x=(E_{x})^*\quad \forall x\in M
			\end{align*}
			und für eine Trivialisierung $(\phi,U)$ von $E$, ist die folgende Abbildung eine Trivialisierung des dualen Bündels:
			\begin{align*}
				\phi^{\prime}\colon(\pi^{\prime})^{-1}(U)&\rightarrow U\times (\R^n)^*\\
				\lambda&\mapsto\left(x,\lambda\circ(\pr_2\circ\phi\vert_{\pi^{-1}(\lbrace x\rbrace)})^{-1}\right)
			\end{align*}
			wobei $\lambda\in E_x^*$. Trivialisierungswechsel sind (unter Identifikation von $\R^n$ mit Spalten- und $(\R^n)^*$ mit Zeilenvektoren) durch $\tau^{\prime}=\tau^{-1}$ gegeben, sodass $(x,\lambda)\mapsto(x,\lambda\tau^{\prime}(x))$.
		\end{defn}
		\begin{bsp}
			Mit obiger Konstruktion können wir aus dem Tangentialbündel $TM$ das \emph{Kotangentialbündel} $T^*M$ gewinnen. Wie wir später sehen werden, ergeben sich in Kombination mit den folgenden Konstruktionen viele neue Strukturen.
		\end{bsp}
		\begin{defn}[Whitney-Summe]
			Die \emph{Whitney-Summe} $(E_a\oplus E_b ,M,\pi,\R^{n_a+n_b})$ ist ein Vektorbündel gegeben durch
			\begin{align*}
				E_a\oplus E_b&:=\bigcup_{x\in M}E_{a,x}\oplus E_{b,x}\\
				\pi&\colon E_a\oplus E_b\rightarrow M\\
				(\pi)^{-1}(x)&=(E_a\oplus E_b)_x=E_{a,x}\oplus E_{b,x}\quad \forall x\in M
			\end{align*}
			und für Trivialisierungen $(\phi_a,U),(\phi_b,U)$ ist die folgende Abbildung eine Trivialisierung der Whitney-Summe:
			\begin{align*}
				\phi\colon\pi^{-1}(U)&\rightarrow U\times \R^{n_a+n_b}\\
				v_a\oplus v_b&\mapsto (\pi_a(v_a), \pr_2(\phi_a(v_a))\oplus\pr_2(\phi_b(v_b)))
			\end{align*}
			Trivialisierungswechsel sind (wieder unter Verwendung von Spaltenvektoren) durch die folgende Blockdiagonalmatrix gegeben: 
			\begin{equation}
				\tau=\left(\begin{array}{cc}\tau_a&0\\0&\tau_b\\ \end{array}\right)
			\end{equation}
		\end{defn}
		\begin{defn}[Tensorprodukt]
			Das \emph{Tensorprodukt} $(E_a\otimes E_b ,M,\pi,\R^{n_a\cdot n_b})$ von Vektorbündeln ist ein Vektorbündel gegeben durch
			\begin{align*}
				E_a\otimes E_b&:=\bigcup_{x\in M}E_{a,x}\otimes E_{b,x}\\
				\pi&\colon E_a\otimes E_b\rightarrow M\\
				(\pi)^{-1}(x)&=(E_a\otimes E_b)_x=E_{a,x}\otimes E_{b,x}\quad \forall x\in M
			\end{align*}
			und für Trivialisierungen $(\phi_a,U),(\phi_b,U)$ ist die folgende Abbildung eine Trivialisierung des Tensorprodukts:
			\begin{align*}
				\phi_a\otimes\phi_b\colon\pi^{-1}(U)&\rightarrow U\times \R^{n_a\cdot n_b}\\
				v_a\otimes v_b&\mapsto (\pi_a(v_a), \pr_2(\phi_a(v_a))\otimes\pr_2(\phi_b(v_b)))
			\end{align*}
			Die Übergangsfunktionen des Tensorproduktes sind durch das Tensorprodukt der Übergangsfunktionen gegeben: $\tau=\tau_a\otimes\tau_b$.
		\end{defn}
		\todo{Tensorprodukt von VR}
		\begin{defn}[Rückzug von Vektorbündeln]
			Sei $f\colon N\rightarrow M$.
			
			Das \emph{entlang $f$ zurückgezogene Vektoründel} $(f^*E,\pi_f,N, F)$ ist gegeben durch:
			\begin{align*}
				f^*E&:=\bigcup _{x\in N} E_{f(x)}\\
				\pi_f&\colon f^*E\rightarrow N\\
				(\pi_f)^{-1}(x)&=(f^*E)_x=E_{f(x)}\quad\forall x\in N
			\end{align*}
			und für $x\in N$ existiert eine Trivialisierung $(\phi,U)$ um $f(x)\in M$ und dannist die folgende Abbildung eine Trivialisierung $(\phi_f,f^{-1}(U))$ des zurückgezogenen Bündels um $x\in N$:
			\begin{align*}
				\phi_f \colon (\pi_f)^{-1}(f^{-1}(U))&\rightarrow f^{-1}(U)\times\R^n\\
				\underbrace{v}_{\in (f^*(E))_x=E_{f(x)}}&\mapsto (\pi_f(v),\pr_2(\phi(v)))
			\end{align*}
			Die Übergangsfunktionen sind identisch zu denen des ursprünglichen Bündels.
		\end{defn}
		Mit dem Rückzug eines Vektorbündels geht auch ein Rückzug seiner Schnitte einher.
		\begin{defn}[Rückzug von Schnitten]
			Sei $f:N\rightarrow M$, $\sigma\in\Gamma(E)$.
			
			Der \emph{Rückzug eines Schnittes} $f^*\sigma$ ist folgendermaßen definiert:
			\begin{align*}
				f^*\sigma\colon N &\rightarrow f^*E,\\
				x &\mapsto \sigma(f(x))=: (f^*\sigma)(x)
			\end{align*}
			Damit ist $f^*\sigma\in\Gamma(f^*E)$, insbesondere differenzierbar. Wir bezeichnen die Menge der zurückgezogenen Schnitte mit $f^*(\Gamma(E))\subset\Gamma(f^*E)$.
		\end{defn}
		\begin{lemma}\label{lemma:Zurückziehen_von_Schnitten}
			Sei $f:N\rightarrow M$.
			
			Die zurückgezogenen Schnitte $f^*(\Gamma(E))$ erzeugen durch $\sm(N)$-Linearkombination die Schnitte des zurückgezogenen Bündels $\Gamma(f^*E)$.
			\begin{proof}
				Übung. Hinweis: Betrachte lokale Rahmen.
			\end{proof}
		\end{lemma}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Vektorfelder}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Grundlegendes}
Definition: Schnitt im Tangentialbündel. Zeigen, dass äquivalent zu (globalen) Derivationen von $\sC(M)$. (Dazu vorher als Lemma: Punktweise Derivationen von $\sC(M)$ lassen sich zu Derivationen von Keimen \glqq lokalisieren\grqq\ via bump functions.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Pushforward und Kommutator}
Definitionen

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Integralkurven und die Lie-Ableitung}
Definition von Integralkurven, Existenz per Picard-Lindelöf. Definition Fluss, Eigenschaften. Defn. Lie-Ableitung (für Funktionen und Vektorfelder). Zeigen, dass Ableitung / Kommutator.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Lie-Gruppen}
	\section{Grundlagen}
		\begin{defn}[Lie-Gruppe]
			Eine \emph{Lie-Gruppe} ist eine differenzierbare Mannigfaltigkeit $G$ mit einer Gruppenstruktur, sodass die Verknüpfung $\cdot\colon G\times G\rightarrow G, (g,h)\mapsto g\cdot h$ und die Inversion ${i\colon G\rightarrow G}, {g\mapsto g^{-1}}$ glatte Abbildungen sind.
			
			Wir definieren die \emph{Linkstranslation} entlang $g$:
			\begin{equation}
				l_g\colon G\to G, h\mapsto g\cdot h
			\end{equation}
			
			Es gelten $(l_g)^{-1}=l_{g^{-1}}$ und $l_g\circ l_h=l_{g\cdot h}$, also ist $l\colon G\rightarrow \mathrm{Aut}(G)$ ein Gruppenhomomorphismus.
			
			Analog lassen sich auch die \emph{Rechtstranslation} $r_g$ (mit $r_g\circ r_h=r_{h\cdot g}$) und die \emph{Konjugation} $c_g:= r_{g^{-1}}\circ l_g$ definieren. Rechts- und Linkstranslationen kommutieren und sind (Anti-) Automorphismen der Lie-Gruppe.
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item $\R^n$ ist zusammen mit der Addition von Vektoren eine Lie-Gruppe.
				\item $\GL(V)$ ist für $n=\dim_{\R} V$ eine $n^2$-dimensionale und $\mathrm{SL}(n,\R)$ eine $(n^2-1)$-dimensionale Lie-Gruppe (Die komplexen Versionen haben die doppelte Dimension). Weitere Beispiele sind die orthogonalen und unitären Gruppen $\mathrm{O}(n)$ ($n(n-1)/2$-dimensional), $\mathrm{SO}(n)$ ($n(n-1)/2$), $\mathrm{U}(n)$ ($n^2$) und $\mathrm{SU}(n)$ ($n^2-1$).
				\item $S^1\cong \lbrace z\in \mathbb{C}\mid zz^*=1\rbrace$ bekommt durch die Multiplikation in der komplexen Ebene eine Gruppenstruktur und ist damit eine Lie-Gruppe (nämlich gerade $\mathrm{U}(1)$). 
			\end{enumerate}
			
		\end{bsp}
		Sei $G$ von nun an eine Lie-Gruppe mit neutralem Element $e$.
		\begin{defn}[Linksinvariante Vektorfelder]
			Ein \emph{linksinvariantes Vektorfeld} ist ein Vektorfeld $X\in\mathfrak{X}(G)$, das \glqq invariant\grqq\ unter dem push-forward von Linkstranslationen ist. Das heißt, dass folgende Gleichung gilt:
			\begin{equation*}
				\left((l_g)_*X\right)_h\stackrel{\text{Def.}}{=}\DD l_g\vert_{g^{-1}\cdot h}X_{g^{-1}\cdot h}=X_h
			\end{equation*}
			Die Menge der linksinvarianten Vektorfelder heißt $\vf^L(G)$.
		\end{defn}
		\begin{satz}
			Die linksinvarianten Vektorfelder bilden eine endlich-dimensionale Unteralgebra der Algebra der Vektorfelder (mit dem Kommutator als Verknüpfung).
			
			Sie ist als Vektorraum isomorph zum Tangentialraum des neutralen Elements $T_eG$.
			\begin{proof}
				Zum Beweis konstruieren wir den kanonischen Isomorphismus und zeigen, dass die linksinvarianten Vektorfelder unter Bildung von Kommutatoren abgeschlossen sind:
				\begin{align}
					\Psi&\colon\vf^L(G)\to T_eG, X\mapsto X_e\nonumber\\
					L&\colon T_eG\rightarrow \vf^L(G), v\mapsto (g\mapsto \DD l_g\vert_e v)\label{def:kan_Iso}
				\end{align}\kommB{Ist $L$ ein guter Name bzw. gibt es da einen üblichen?}
				$L$ ist wohldefiniert, denn für $v\in T_eG$ und $g,h\in G$ gilt:
				\begin{align*}
					\left((l_g)_*L(v)\right)_h&=\DD l_g\vert_{g^{-1}\cdot h}L(v)_{g^{-1}\cdot h}\\
					&=\DD l_g\vert_{g^{-1}\cdot h}\DD (l_{g^{-1}\cdot h}\vert_e v)\\
					\text{(Kettenregel)}\quad &=\DD\left(l_g\circ l_{g^{-1}}\right)\big\vert _h\DD l_h\vert_e v\\
					&=\DD l_h\vert_e v\\
					&=L(v)_h
				\end{align*}
				Außerdem gilt $\Psi\circ L=\id_{T_eG}$:
				\begin{align*}
					\Psi(L(v))= (g\mapsto \DD l_g\vert_e v)_e=\DD l_e\vert_e v=v
				\end{align*}
				und die Umkehrung $L(\Psi(X))=X$ wird punktweise durch Ausnutzen der Linksinvarianz klar:
				\begin{align*}
					X_g&=\DD l_g\vert_{g^{-1}\cdot g}X_{g^{-1}\cdot g}=\left((l_g)_*X\right)_g\\
					&=\DD l_g\vert_e X_e\\
					&=L(X_e)_g
				\end{align*}
				Beide Abbildungen sind linear, für $L$ gilt dies, da das Differential linear ist.
				
				Nun bleibt zu zeigen, dass der Kommutator zweier linksinvarianter Vektorfelder linksinvariant ist (Übung).
			\end{proof}
		\end{satz}
		\begin{defn}[Lie-Algebra]
			Die \emph{Lie-Algebra} einer Lie-Gruppe ist der Vektorraum $\mathfrak{g}:=T_eG$ mit der folgenden Verknüpfung:
			\begin{align*}
				\left[.,.\right]\mathfrak{g}\times \mathfrak{g}\rightarrow \mathfrak{g}, (v,w)\mapsto \left[v,w\right]:=\left[L(v),L(w)\right]_e
			\end{align*}
			mit dem kanonischen Isomorphismus $L\colon \mathfrak{g}\to \vf^L(G)$ aus Gleichung (\ref{def:kan_Iso}). Diese Verkettung ist bilinear und antisymmetrisch nach Konstruktion.
		\end{defn}
		\begin{bsp}\hfill
			Die Lie-Algebra der $\GL(V)$ ist der Vektorraum der Endomorphismen $\End(V)$. Dies wird klar, wenn man $\GL(n,\R)$ als (offene) Teilmenge des $\R^{n^2}$ betrachtet: Der Tangentialraum ist dann kanonisch $\R^{n^2}\cong\End(\R^n)$ und durch Basiswahl erhält man die Identifizierung für beliebige (reelle) Vektorräume.
		\end{bsp}
		\begin{lemma}
			Linksinvariante Vektorfelder sind vollständig, das heißt, ihre Integralkurven können auf ganz $\R$ fortgesetzt werden.
			\begin{proof}
				$\gamma_g\colon I_g\rightarrow G$ Integralkurve in $g\in G$ $\Rightarrow \gamma^{\prime}\colon I_g\rightarrow G, t\mapsto l_h(\gamma_g(t))$ ist Integralkurve in $h\cdot g\;\forall h\in\gamma_g(I_g)$ (Kettenregel) $\rightarrow$ Setze $\gamma_g$ fort.
			\end{proof}\todo{Ausformulieren mit Notation des vorherigen Kapitels}
		\end{lemma}
	\section{Die Exponentialabbildung}
		\begin{defn}[Exponentialabbildung]
			Die \emph{Exponentialabbildung} $\exp\colon\mathfrak{g}\rightarrow G$ ist durch den Fluss der linksinvarianten Vektorfelder definiert:
			\begin{equation*}
				\exp(v):=\Phi_1^{L(v)}(e)
			\end{equation*}\kommB{Notation des vorherigen Kapitels übernehmen!}
			Dies entspricht gerade der Integralkurve von $L(v)$ in $e$ ausgewertet an der Stelle $1$.
		\end{defn}
		\begin{lemma}\label{lemma:Eigenschaften_exp}
			Die Exponentialabbildung besitzt die folgenden Eigenschaften:
			\begin{enumerate}[label=\arabic*]
				\item $\frac{d}{dt}\exp(tv)\Big\vert_{t=0}=v\quad\forall v\in\mathfrak{g}$
				\item $\exp(0)=e$
				\item $\exp((s+t)v)=\exp(sv)\cdot\exp(tv) \quad\forall v\in\mathfrak{g}, s,t\in \R$
			\end{enumerate}
			\begin{proof}
				Übung. (Für die dritte Eigenschaft, konstruiere zwei Integralkurven in $\exp(sv)$) \kommB{Hinweis: Zum Beweis der dritten Eigenschaft hilft der Beweis der Vollständigkeit von linksinvarianten Vektorfeldern und die Eigenschaften von Integralkurven bzgl. Skalierung.}
			\end{proof}
		\end{lemma}
		\begin{lemma}[Fluss linksinvarianter Vektorfelder]\label{lemma:Fluss_linksinvarianter_Vektorfelder}
			Sei $X\in\vf^L(G)$.
			
			Der Fluss von $X$ ist durch die Exponentialabbilding wie folgt gegeben:
			\begin{align*}
				\Phi^X_t(p)=p\cdot \exp(tX_e) \; =l_p(\exp(tX_e))=r_{\exp(tX_e)}(p)
			\end{align*}
			\begin{proof}
				Es gilt $l_p(\exp(0))=p=\Phi^X_0(p)$. Wir zeigen nun, dass $l_p(\exp(tX_e)$ $X$ erzeugt und die Aussage folgt dann aufgrund der Eindeutigkeit der Lösung von Differentialgleichungen (oder von Integralkurven).
				\begin{align*}
					\frac{d}{dt}l_p(\exp(tX_e))&=\frac{d}{ds}l_{p\cdot\exp(tX_e)}(\exp(sX_e))\Big\vert_{s=0}\\
					&=\DD l_{p\cdot\exp(tX_e)}\vert_eX_e\\
					&=X_{p\cdot\exp(tX_e)}
				\end{align*}
			\end{proof}
		\end{lemma}
		\begin{lemma}
			Für einen Lie-Gruppenhomomorphismus $\phi\colon G\rightarrow H$ (einen glatten Gruppenhomomorphismus zwischen Lie-Gruppen) kommutiert das folgende Diagramm:
			\begin{center}
			\begin{tikzpicture}
				\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{\mathfrak{g} & \mathfrak{h} \\
     G&H \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$\DD\phi\vert_e$} (m-1-2)
  							edge node [left]{$\exp$} (m-2-1)
  					(m-1-2) edge node [right]{$\exp$} (m-2-2)
  					(m-2-1) edge node [above]{$\phi$} (m-2-2)
  					;
			\end{tikzpicture}
			\end{center}
			Man kann zeigen, dass die Abbildung $\DD\phi\vert_e$ ein Lie-Algebrenhomomorphismus ist, also mit den Kommutatoren verträglich ist.
			\begin{proof}
				Wir wollen zeigen, dass $\exp(D\phi\vert_e v)=\phi(\exp(v))\forall v\in\mathfrak{g}$ gilt. Sei $v\in\mathfrak{g}$, ${\gamma\colon [0,1]\rightarrow G}$,$ \gamma(t):=\phi(\exp(tv))$ und zeige nun, dass $\gamma$ die Integralkurve von $L(\DD\phi\vert_e v)$ in $e\in H$ ist:
				\begin{align*}
					\gamma'(t)&=\frac{d}{dt}(\phi(\exp(tv))\\
					&=\DD\phi\vert_{\exp(tv)}\DD l_{\exp(tv)}\vert_e v\\
					&=\DD(\phi\circ l_{\exp(tv)})\vert_e v\\
					&=\DD(l_{\phi(\exp(tv))}\circ\phi)\vert_e v\\
					&=\DD l_{\gamma(t)}\vert_e\DD\phi\vert_ev\\
					&=L(\DD\phi\vert_e v)_{\gamma(t)}
				\end{align*}
				Daraus folgt nun insbesondere $\phi(\exp(v))=\gamma(1)=\exp(\DD\phi\vert_e v)$.
			\end{proof}
		\end{lemma}
		\begin{bem}\label{bem:exp_induziert_Abbildungen}
			Aufgrund von Lemma \ref{lemma:Eigenschaften_exp} lassen sich also die induzierten Lie-Algebrenhomomorphismen $\DD\phi\vert_e$ wie folgt berechnen:
			\begin{align*}
				\DD\phi\vert_e v&=\frac{d}{dt}\exp(t \DD\phi\vert_e v)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\phi(\exp(tv))\Big\vert_{t=0}
			\end{align*}
		\end{bem}
	\section{Wirkungen und Darstellungen}
		\begin{defn}[Gruppenwirkung]
			Sei $M$ eine Mannigfaltigkeit, $G$ eine Lie-Gruppe.
			
			Eine \emph{Rechtswirkung} ist eine Abbildung 
			\begin{gather*}
					\tril\colon M \times G \rightarrow M, \quad (p,g) \mapsto p\tril g 
				\intertext{die mit der Verknüpfung im folgenden Sinne kompatibel ist:}
					(p \tril g)\tril h = p\tril (g\cdot h) \quad \forall p\in M, g,h \in G
				\end{gather*}
				Außerdem gelte $p\tril e=p$ für alle Punkte $p\in M$.
				
				Analog definiert man eine \emph{Linkswirkung} $\trir \colon G \times M \rightarrow M,\; (p,g)\mapsto g\trir p$, sodass 
				\begin{equation*}
					h\trir (g\trir p) =(h\cdot g)\trir p \quad \forall p\in M, g,h \in G
				\end{equation*}
				wobei die Reihenfolge umgekehrt ist und es gelte $e\trir p=p$ für alle Punkte $p\in M$.
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Rechts- und Linkstranslationen sind Rechts- und Linkswirkungen auf der Lie-Gruppe selbst.
				\item Eine \emph{Darstellung} ist ein Gruppenhomomorphismus $\rho\colon G\rightarrow \GL(V)$ für einem Vektorraum $V$. Damit ist $V\times G\rightarrow V, (v,g)\mapsto \rho(g)v$ eine Linkswirkung (da nach Definition eines Gruppenhomomorphismus gerade $\rho(g)\rho(h)=\rho(g\cdot h) \forall g,h\in G$ und $\rho(e)=\id_V$ gelten).
				\item Schreibt man die Elemente der obigen Beispiele von Lie-Gruppen in ihrer üblichen Form als $n\times n$-Matrizen, so erhält man (sogenannte fundamentale) Darstellungen durch die Matrixmultiplikation mit Elementen von $\R^n$ bzw. $\mathbb{C}^n$.
			\end{enumerate}
		\end{bsp}
		\begin{defn}[Die Adjungierte Darstellung]\hfill
		
			Die Konjugation liefert eine Darstellung jeder Lie-Gruppe auf ihrer Lie-Algebra, die sogenannte \emph{Adjungierte Darstellung}:
			\begin{align*}
				\Ad\colon G\rightarrow \GL(\mathfrak{g}), g\mapsto \DD c_g\vert_e
			\end{align*}
			Man erhält darüber hinaus auch eine Darstellung der Lie-Algebra selbst:
			\begin{align*}
				\ad:=\DD\Ad\vert_e\colon\mathfrak{g}\rightarrow\End(\mathfrak{g}),
			\end{align*}
			Mit Lemma \ref{lemma:Fluss_linksinvarianter_Vektorfelder} und Bemerkung \ref{bem:exp_induziert_Abbildungen} folgt dann:
			\begin{align*}
				\ad_v(w)&=\frac{d}{dt}\Ad_{\exp(tv)}(w)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD c_{\exp(tv)}\vert_e w\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD r_{\exp(-tv)}\vert_{\exp(tv)}\DD l_{\exp(tv)}\vert_e w\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD r_{\exp(-tv)}\vert_{\exp(tv)}L(w)_{\exp(tv)}\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD \Phi_{-t}^{L(v)}\vert_{\Phi^{L(v)}_t(e)}L(w)_{\Phi^{L(v)}_t(e)}\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\left(\Phi_{-t}^{L(v)}\right)_*L(w)\right)_e\Big\vert_{t=0}\\
				&=\mathcal{L}_{L(v)}(L(w))_e\\
				&=\left[v,w\right]
			\end{align*}
			Also ist $\ad_v$ eine lineare Abbildung. Beachte: $\ad$ ist auch \glqq im ersten Argument\grqq\ linear, also $\ad_{v+w}=\ad_v+\ad_w \quad\forall v,w\in\mathfrak{g}$ und ist damit ein Gruppenhomomorphismus der Lie-Algebra als additive Gruppe, allerdings keine Abbildung in eine $\GL(V)$ (Man sagt dennoch \glqq induzierte Darstellung\grqq).
		\end{defn}
		\begin{defn}[Killing-Form]
			Die \emph{Killing-Form} ist eine symmetrische Bilinearform, definiert durch:
			\begin{align*}
				B_{\mathfrak{g}}\colon\mathfrak{g}\times\mathfrak{g}\rightarrow\R, (v,w)\mapsto \tr(\ad_v\circ\ad_w).
			\end{align*}
			Die Bilinearität folgt aufgrund der Linearität der Spur und $\ad$ und die Symmetrie aufgrund der Zyklizität der Spur.
		\end{defn}
		\begin{satz}
			Die Killing-Form ist negativ definit genau dann, wenn die Lie-Gruppe kompakt und das Zentrum der Lie-Algebra
			\begin{equation*}
				\mathfrak{z}(\mathfrak{g}):=\lbrace v\in\mathfrak{g}\mid \left[v,w\right]=0\,\forall w\in\mathfrak{g}\rbrace
			\end{equation*}
			trivial ($=\lbrace 0\rbrace$) ist.
		\end{satz}
		\kommB{Idee: Hier noch fundamentale Vektorfelder und adjungierte Darstellung und dann später bei Geodäten bzgl der Killing-form sehen, dass (die Exponentialabbildungen übereinstimmen und damit) die Geodäten gerade Integralkurven linksinvarianter Vektorfelder sind.}
		
		Mit Wirkungen lassen sich auch allgemeiner Vektorfelder von Elementen der Lie-Algebra erzeugen:
		\begin{defn}[Fundamentale Vektorfelder]
			Sei $\trir:G\times M\rightarrow M$ eine Linkswirkung.
			
			Das \emph{fundamentale Vektorfeld} $X^v$ zu einem Element der Lie-Algebra $v\in\mathfrak{g}$ ist durch die folgende Gleichung definiert:
			\begin{align*}
				X^v_p:=\frac{d}{dt}\exp(tv)\trir p\Big\vert_{t=0} \quad\forall p\in M
			\end{align*}
			Beachte, dass dies für die Linkstranslation gerade dem Fluss aus Lemma \ref{lemma:Fluss_linksinvarianter_Vektorfelder} entspricht! Linksinvariante Vektorfelder sind also die fundamentalen Vektorfelder der Lie-Gruppe selbst.
		\end{defn}
		
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Tensorfelder}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Differentialformen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Kovariante Ableitungen}
	\section{Grundlagen}
		\begin{defn}[Kovariante Ableitung]Sei $E$ ein Vektorbündel über $M$.
		
			Eine \emph{kovariante Ableitung} ist eine Abbildung
			\begin{align*}
				\nabla\colon \vf(M)\times\Gamma(E)\rightarrow\Gamma(E), (X,\sigma)\mapsto \nabla_X \sigma,
			\end{align*}
			die die folgenden Eigenschaften erfüllt:
			\begin{enumerate}[label=\arabic*]
				\item $\sm(M)$-Linearität im ersten Argument: 
				\begin{equation*}
					\nabla_{X+fY}\sigma=\nabla_X\sigma+f\nabla_Y \sigma\quad\forall X,Y\in\vf(M), f\in\sm(M),\sigma\in\Gamma(E)
				\end{equation*}
				\item \glqq Derivativität\grqq\ im zweiten Argument: 
				\begin{equation*}
					\nabla_X(f\sigma)=\underbrace{X(f)}_{\in\sm(M)} \sigma+f\nabla_X \sigma\quad\forall X\in\vf(M), f\in\sm(M),\sigma\in\Gamma(E)
				\end{equation*}
			\end{enumerate}
		\end{defn}
		Die kovariante Ableitung ist im Fall des Tangentialbündels ergibt eine weitere Tensorderivation (definiert als Forsetzung ihrer Wirkung auf Vektorfeldern und Funktionen). Ihren besonderen Nutzen sehen wir später im Kontext der Riemannschen Geometrie.
		
		Sei von nun an $\nabla$ eine kovariante Ableitung auf einem Vektorbündel $(E,\pi)$.
		\begin{lemma}\label{lemma:Einschränkung_kovarianter_Ableitungen}
			Sei $U\in M$ offen. 
			
			Es existiert eine eindeutige kovariante Ableitung $\nabla^U\colon\vf(U)\times\Gamma(E\vert_U)\rightarrow \Gamma(E\vert_U)$ sodass $\nabla^U_{X\vert_U}\sigma\vert_U=(\nabla_X\sigma)\vert_U\; \forall X\in\vf(M),\sigma\in\Gamma(E)$ gilt.
			\begin{proof}
				Seien $\nabla'$ und $\nabla''$ kovariante Ableitungen, die die obige Bedingung erfüllen. Wir müssen zeigen, dass diese beiden auf beliebigen lokalen Schnitten und Vektorfeldern identisch sind. 
				
				Da lokale Schnitte und Vektorfelder von Einschränkungen globaler Schnitte und Vektorfelder erzeugt werden, und die Wirkung von Vektorfeldern auf Funktionen ebenfalls nur lokal vom Vektorfeld abhängt, reicht es (aufgrund der $\sm(U)$-Linearität und der Derivativität), die Gleichheit der kovarianten Ableitungen auf Einschränkungen der Schnitte und Vektorfelder zu zeigen. Diese ist jedoch nach Voraussetzung gegeben.
			\end{proof}
		\end{lemma}
		\begin{lemma}[Lokalität kovarianter Ableitungen]
			Seien $X_1,X_2\in\vf(M)$ und $\sigma_1,\sigma_2\in\Gamma(E)$ auf einer Umgebung von $p\in M$ identisch, so gilt:
			\begin{enumerate}
				\item $\left(\nabla_{X_1}\sigma_1\right)(p)=\left(\nabla_{X_2}\sigma_1\right)(p)$
				\item $\left(\nabla_{X_1}\sigma_1\right)(p)=\left(\nabla_{X_1}\sigma_2\right)(p)$
			\end{enumerate}
			\begin{proof}
				Übung. (Für die 2. darf Lemma \ref{lemma:Einschränkung_kovarianter_Ableitungen} verwendet werden.)
			\end{proof}
		\end{lemma}
		Wir wollen noch allgemein untersuchen, wie kovariante Ableitungen in lokalen Trivialisierungen aussehen.
		\begin{lemma}
			Sei $(\sigma_1,\ldots,\sigma_k)$ ein lokaler Rahmen über $U\subset M$ und $\phi\colon\pi^{-1}(U)\rightarrow U\times \R^k$, sodass $\phi(\sigma_i)=e_i$ die Standardbasis ist. Damit ist dann $\mathrm{span}_{\R}\lbrace (\sigma_1)_x, \ldots,(\sigma_k)_x\rbrace=E_x\cong\R^k$ und $\Gamma(E\vert_U)=\mathrm{span}_{\sm(U)}\lbrace \sigma_1,\ldots,\sigma_k\rbrace$.
			
			Die kovariante Ableitung des Rahmens ist wieder ein Schnitt, lässt sich also in Komponenten bezüglich dieses Rahmens schreiben, sodass die kovariante Ableitung bezüglich eines gegebenen Vektorfeldes $X\in\vf(U)$ wie eine Matrix wirkt:
			\begin{align*}
				(A_X)^a_b\sigma_a=\nabla_X\sigma_b
			\end{align*}
			
			Man erhält punktweise ($x\in M$) lineare Abbildungen
			\begin{align*}
				(A_X)_x\colon\R^k&\rightarrow\R^k,\\
				(v^1,\ldots,v^k)&\mapsto \pr_2(\phi((\nabla_X v^i\sigma_i)(x)))=((A_X)_{b,x}^av^b)e_a
			\end{align*}
			wobei die letzte Gleichheit wegen der $\R$-Linearität der kovarianten Ableitung und der Kompatibilität von Rahmen und Trivialisierung folgt. Damit ist $A_X$ ein Schnitt des trivialen Bündels $U\times \End(\R^k)$. Die \emph{Zusammenhangs(eins)form} ist die Abbildung $X\mapsto A_X\in\Gamma(U\times \R^k)$.
			
			Ist zusätzlich $U$ eine Koordinatenumgebung, dann definiert man die \emph{Zusammenhangskoeffeizienten} $A_{ib}^a:=(A_{\partial_i})^a_b$.
			
			Für einen beliebigen lokalen Schnitt $\sigma=f^a\sigma_a\in\Gamma(E\vert_U)$ und ein lokales Vektorfeld $X=g^i\partial_i$ (mit $f^a,g^i\in\sm(U)$) lässt sich die kovariante Ableitung dann folgendermaßen schreiben:
			\begin{align*}
				\nabla_X\sigma=\left( X(f^a)+(A_X)^a_bf^b\right)\sigma_a=g^i\left( \partial_i(f^a)+A^a_{ib}f^b\right)\sigma_a
			\end{align*}
			
			Für Elemente $\rho_c=\tau_c^d\sigma_d$ eines anderen lokalen Rahmens und $\frac{\partial}{\partial y^j}=\frac{\partial x^i}{\partial y^j}\frac{\partial}{\partial x^i}$ einer Koordinatenbasis (wobei im ersten Faktor rechts mit $x^i$ die Koordinatenfunktionen $\varphi^i$ gemeint sind), lassen sich damit auch die Zusammenhangskoeffizienten $B^c_{jd}$ bezüglich des Rahmens $\rho$ und der Koordinaten $y$ berechnen:
			\begin{align*}
				B^c_{jd}&=\frac{\partial x^i}{\partial y^j}\left((\tau^{-1})^c_a\frac{\partial \tau^a_d}{\partial x^i}+(\tau^{-1})^c_aA^a_{ib}\tau^b_d\right)\\
				B_j&= \frac{\partial x^i}{\partial y^j}\left(\tau^{-1}\frac{\partial \tau}{\partial x^i}+\tau^{-1}A_{i}\tau\right)\quad\text{als Matrizen}
			\end{align*}
			Man sieht dies durch Vergleich der Koeffizienten bezüglich der Basen:
			\begin{align*}
				\nabla_{\frac{\partial}{\partial y^j}}\rho_d&=B_{jd}^c\rho_c=B_{jd}^c\tau_c^d\sigma_d\\
				&=\frac{\partial x^i}{\partial y^j} \left(\partial_i(\tau^a_d)+A^a_{ib}\tau^b_d\right)\sigma_a=\frac{\partial x^i}{\partial y^j} \left(\partial_i(\tau^a_d)+A^a_{ib}\tau^b_d\right)(\tau^{-1})^c_a\rho_c
			\end{align*}
			Beachte: Die Zusammenhangskoeffizienten sind nicht Koeffizienten eines Tensors.
		\end{lemma}\kommB[inline]{Ist das hier zu technisch? Wollen/Brauchen wir das (Abgesehen von Beweisen)?}
	\section{Induzierte Zusammenhänge}
		Insbesondere interessieren uns kovariante Ableitungen entlang von Kurven $\gamma\colon I\rightarrow M$. Dies entspricht einer kovarianten Ableitung auf dem auf das Intervall $I$ zurückgezogenen Bündel. Wir müssen also die kovariante Ableitung ebenfalls zurückziehen.
		\begin{satz}[Rückzug von kovarianten Ableitungen]
			Sei $f\colon N\rightarrow M$.
			
			Für eine kovariante Ableitung $\nabla$ auf dem Vektorbündel $(E,\pi)$ gilt: $\exists!$ kovariante Ableitung $f^*\nabla\colon\vf(N)\times\Gamma(f^*E)\rightarrow \Gamma(f^*E)$ sodass für alle $X\in\vf(N),\sigma\in\Gamma(E), {p \in N}$ gilt:
			\begin{equation*}
				\left(\left(f^*\nabla\right)_X(f^*\sigma)\right)(p)=f^*\left(\nabla_Y\sigma\right)(p)
			\end{equation*}
			mit einem Vektorfeld $Y\in\vf(M)$ sodass $Y_{f(p)}=\DD f\vert_p X_p$. Diese kovariante Ableitung ist der \emph{Rückzug der kovarianten Ableitung} $\nabla$.
			
			Seien $A_{ib}^a$ die Zusammenhangskoeffizienten von $\nabla$ in einer Koordinatenumgebung $U\subset M$ und bezüglich eines Rahmens $\sigma_a$.
			Fasst man $f$ in Koordinaten $u\in V\subset N$ (mit $f(V)\subset U$) als Funktion $f\colon\R^n\rightarrow\R^m$ auf, so sind die Zusammenhangskoeffizienten der zurückgezogenen kovarianten Ableitung bezüglich des Rahmens $f^*\sigma_a$ durch $\frac{\partial f^i}{\partial u^j}A_{ib}^a$ gegeben.
			\begin{proof}
				Auf $\vf(N)\times f^*(\Gamma(E))$ ist der Rückzug wegen der Lokalität der kovarianten Ableitungen wohldefiniert (insbesondere unabhängig von der Wahl $Y\in\vf(M)$). Linearität und Derivativität folgen aus den entsprechenden Eigenschaften der ursprünglichen kovarianten Ableitung und der Linearität des Differentials. Man setzt die kovariante Ableitung lokal derivativ auf $\Gamma(f^*E\vert_U)$ fort (da $f^*(\Gamma(E\vert_U))$ alle Schnitte $\Gamma(f^*E\vert_U)$ erzeugt). Eindeutigkeit ohne Beweis.
			\end{proof}
		\end{satz}
		\begin{defn}
			Für eine Kurve $\gamma\colon I\rightarrow M$ sei $\partial_t$ das Vektorfeld, das von der Kurve $id_I\colon I\rightarrow I$ erzeugt wird. Man erhält dann eine kovariante Ableitung auf $I$:
			\begin{align*}
				\nabla_t:=(\gamma^*\nabla)_{\partial_t}\colon\Gamma(\gamma^*E)\rightarrow\Gamma(\gamma^*E)
			\end{align*}
			Das \glqq Auswerten\grqq\ an $\partial_t$ schränkt die Allgemeinheit nicht ein, da dieses Vektorfeld ja einen globalen Rahmen des Tangentialbündels $TI$ darstellt.
			
			Weiter können wir $X:=\dot{\gamma}$ als Schnitt von $\gamma^*(TM)$ auffassen mit $X_t=\dot{\gamma}(t)$.  
		\end{defn}
	\section{Geodäten}
		\begin{defn}[Parallele Schnitte]
			Sei $\gamma\colon I\rightarrow M$ eine Kurve.
			
			Ein entlang $\gamma$ \emph{kovariant konstanter} (auch \emph{horizontaler} oder \emph{paralleler}) Schnitt ist ein $\sigma\in\Gamma(\gamma^*E)$, sodass gilt:
			\begin{align*}
				\nabla_t\sigma=0
			\end{align*}
		\end{defn}
		\begin{lemma}
			Sei $\gamma\colon I\rightarrow M$ eine Kurve, $a\in I$, $v\in E_{\gamma(a)}$.
			
			Es existiert genau ein paralleler Schnitt $\sigma\in \Gamma(\gamma^*E)$ mit $\sigma(a)=v$.
			
			Der Paralleltransport ist der folgende Isomorphismus von Vektorräumen:
			\begin{align*}
				P_{a}(b)\colon E_{\gamma(a)}\rightarrow E_{\gamma(b)}, v\mapsto \sigma(b)
			\end{align*}
			Mit entsprechendem Schnitt $\sigma$ wie oben, in Abhängigkeit von $v$.
			\begin{proof}
				In Koordinaten von $M$ und einem lokalen Rahmen $\sigma_c$ löst $\sigma=f^c\gamma^*\sigma_c$ die folgende homogene, lineare Differentialgleichung:
				\begin{align*}
					\dot{f}^c+A^c_{id}\dot{\gamma}^i f^d=0
				\end{align*}
				Man erhält die eindeutige Lösung $f^c$ mit $f^c(a)=v^c$ und $\sigma:=f^c\sigma_c$ lässt sich durch \glqq Verkleben\grqq\ von Lösungen auf ganz $I$ fortsetzen. (Man kann nach Lemma \ref{kor:Vektorbündel_über_Intervallen} erst $\gamma^*E$ global trivialisieren und die entsprechende Differentialgleichung dort lösen.)
				
				Der Paralleltransport ist wohldefiniert wegen der Eindeutigkeit von Lösungen linearer Differentialgleichungen. Aufgrund der Homogenität und Linearität ist der Paralleltransport außerdem linear. Für die Isomorphie wählt man $b$ und $\sigma(b)$ als neue Anfangsbedingungen. Dann ist eben $\sigma$ wieder eine Lösung und damit $P_a(b)P_b(a)=\id_{E_{\gamma(a)}}$ und analog $P_b(a)P_a(b)=\id_{E_{\gamma(b)}}$.
			\end{proof}
		\end{lemma}
		Dieses Lemma gibt uns eine Anschauung davon, was die kovariante Ableitung leistet: Sie schreibt einen Zusammenhang zwischen einzelnen Fasern vor, indem sie anschaulich angibt, wann ein Schnitt entlang einer Kurve nicht variiert (Manchmal wird die kovariante Ableitung deshalb auch \glqq Zusammenhang\grqq\ genannt. Wir bleiben bei unserer Konvention).
		
		Man kann auch andersherum eine kovariante Ableitung aus einem Paralleltransport gewinnen:
		\begin{lemma}
			Sei $\gamma\colon I\rightarrow M$ eine Kurve, $a=0\in I$, $x=\gamma(0)$.
			
			Der Paralleltransport erfüllt die folgende Eigenschaft:
			\begin{align*}
				\frac{d}{dt} P^{-1}_0(t) \sigma(\gamma(t))\Big\vert_{t=0}=(\nabla_{\dot{\gamma}(0)}\sigma) (x)
			\end{align*}
			Aus den obigen Aussagen ist klar, dass dies nur von $\dot{\gamma}(0)$ abhängt, nicht von der ganzen Kurve. Dies erläutert anschaulich, warum man durch diese Formal auch eine kovariante Ableitung definieren kann.
		\end{lemma}
		

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Riemann'sche Geometrie}
	\section{Grundlagen}
		Wir wollen das Konzept eines Skalarproduktes auf Vektorräumen auf Vektorbündel übertragen.
		\begin{defn}[Bündelmetrik]
			Sei $(E,\pi)$ ein Vektorbündel über $M$.
			
			
			Eine \emph{Bündelmetrik} ist ein eine Abbildung
			\begin{equation*}
				g\colon \Gamma(E)\times\Gamma(E)\rightarrow \sm(M), (\sigma^1,\sigma^2)\mapsto (p\mapsto g_p(\sigma^1_p,\sigma^2_p)),
			\end{equation*}
			(also $g\in\Gamma(E^*\otimes E^*)$) sodass an jedem Punkt $p\in M$ die Abbildung $g_p\colon E_p\times E_p\rightarrow \R$ eine nicht-degenerierte, symmetrische Bilinearform mit von $p$ unabhängiger Signatur ist.
		\end{defn}
		\begin{defn}[Riemann'sche Metrik]
			Eine \emph{Riemann'sche Metrik} ist ein Bündelmetrik $g$ auf dem Tangentialbündel, sodass $g_p$ fü jeden Punkt $p\in M$ ein Skalarprodukt ist (also insbesondere positiv definit).
			
			In Koordinaten ist die Metrik durch eine positiv definite, symmetrische Matrix $g_{ij}$ gegeben, sodass $g=g_{ij}dx^i\otimes dx^j$ gilt. Die (Komponenten der) Inversen Matrix werden mit $g^{ij}$ bezeichnet, sodass $g_{ij}g^{jk}=\delta^k_i$.
		\end{defn}
		\begin{bem}
			Man sagt auch \emph{pseudo-Riemann'sche Metrik} für eine beliebige Bündelmetrik auf dem Tangentialbündel. Physik!
		\end{bem}
		\begin{satz}
			Auf jeder Mannigfaltigkeit existiert eine Riemann'sche Metrik.
		\end{satz}
		Wie für Vektorräume induziert ein Skalarprodukt einen Isomorphismus zum Dualraum:
		\begin{defn}
			Die \emph{metrischen Typänderungen} sind die folgenden punktweise definierten Abbildungen:
			\begin{align*}
				^{\flat}&\colon T_pM\rightarrow T_p^*M, v\mapsto v^{\flat}:=g_p(v,\cdot)\\
				^{\sharp}&\colon T_p^*M\rightarrow T_pM, \lambda\mapsto \lambda^{\sharp}
			\end{align*}
			wobei $\lambda^{\sharp}\in T_pM$ der durch die Gleichung $\lambda(v)=g_p(\lambda^{\sharp},v)\forall v\in T_pM$ eindeutig definierte Vektor ist.
			
			Es gelten $(v^{\flat})^{\sharp}=v\;\forall v\in T_pM$ und $(\lambda^{\sharp})^{\flat}=\lambda\;\forall\lambda\in T_p^*M$.
			
			Man erhält dadurch einen Isomorphismus von Vektorbündeln $TM\cong T^*M$ und einen Isomorphismus von $\sm(M)$-Moduln $\vf(M)\cong \Omega^1(M)$ (Wegen der $\sm(M)$-Linearität der Metrik).
			
			In Koordinaten wirkt die metrische Typänderung auf Komponenten auf einfache Weise. Sei $X\in\vf(M), \omega\in\Omega^1(M)$:
			\begin{align*}
				(X^{\flat})_i&=g_{ij}X^j\\
				(\omega^{\sharp})^i&=g^{ij}\omega_j
			\end{align*}
			wobei $g^{ij}$ wieder die Komponenten der Inversen Matrix bezeichnet.
		\end{defn}
	\section{Metrik und Zusammenhang}
	\section{Der Satz von Hopf-Rinow}
	\section{Anwendung: Lie-Gruppen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Integration auf Mannigfaltigkeiten}


\end{document}