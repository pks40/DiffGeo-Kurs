% !TeX spellcheck = de_DE
\documentclass[a4paper]{scrreprt}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[sc]{mathpazo}
\linespread{1.05}
\usepackage{exscale} % To scale mathematical symbols correctly while using T1
\usepackage{amsmath,amsthm,amssymb,dsfont}
\usepackage{tikz}
	\usetikzlibrary{matrix}
\usepackage[ngerman]{babel}
\usepackage{enumitem}
\usepackage{microtype} % Microtypography!
\usepackage{epigraph}
\usepackage{hyperref}
\usepackage{todonotes}

\setlength{\epigraphwidth}{0.6\textwidth}

\numberwithin{equation}{chapter}

\newcommand{\D}{\mathrm{d}}
\newcommand{\DD}{\mathrm{D}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\diff}{:\Longleftrightarrow}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Diff}{Diff}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\pr}{pr}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\tr}{tr}

\newcommand{\R}{\mathbb{R}}
\newcommand{\sC}{\mathcal{C}^{\infty}}
\newcommand{\sm}{\mathcal{F}}
\newcommand{\vf}{\mathfrak{X}}
\newcommand{\tril}{\vartriangleleft}
\newcommand{\trir}{\vartriangleright}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{lemma}[defn]{Lemma}
\newtheorem{prop}[defn]{Proposition}
\newtheorem{satz}[defn]{Satz}
\newtheorem{kor}[defn]{Korollar}
\newtheorem{bem}[defn]{Bemerkung}
\newtheorem{bsp}[defn]{Beispiel}
\newtheorem{nota}[defn]{Notation}

% Kommentare
\newcommand{\kommP}[2][noinline]{\todo[#1,color=green!40]{#2}}
\newcommand{\kommB}[2][noinline]{\todo[#1,color=blue!20]{#2}}

\title{Einführung in die Differentialgeometrie}
\subtitle{Kurs auf der CdE-WinterAkademie 2018/19}
\author{Benjamin Haake, Philip Schwartz}
\date{November 2018}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{chapter}{-1}
\chapter{Einleitung}
\epigraph{Differentialgeometrie ist die Lehre von Eigenschaften, die invariant unter Notationswechsel sind.}{\textsc{Altes chinesisches Sprichwort}}

Verallgemeinerung von Kurven, Flächen und so. Extrem wichtig innerhalb der Mathematik und auch in quasi allen Anwendungsgebieten, insb. der theoretischen Physik (ART, Eichtheorien, alles!).

\section{Bekannte Konzepte, Notationen etc.}

\subsection{Lineare Algebra}

\begin{nota}
	Für einen Vektorraum $V$ über einem Körper $K$ bezeichnet \[V^* := \mathrm{Hom}(V,K) = \{f\colon V \to K : f \text{ linear}\}\] den Dualraum von $V$.
\end{nota}

\subsection{Mehrdimensionale Analysis}
\begin{nota}
	Punkte im $\mathbb R^n$ schreiben wir als $x = (x^1, \dots, x^n)$. Die Vektoren der Standardbasis von $\mathbb R^n$ schreiben wir als $\e_1, \dots, \e_n \in \mathbb R^n$, also \[\e_i = (0,\dots,\underset{i}{1},\dots,0).\]

	Sei $U \subset \mathbb R^n$ eine offene Menge und $f\colon U \to \mathbb R$ eine differenzierbare Abbildung. Die partielle Ableitung von $f$ nach der $i$-ten Komponente schreiben wir als $\partial_i f$, d.\,h. es ist
	\[(\partial_i f)(x) = \lim_{h\to 0} \frac{f(x + h \e_i) - f(x)}{h}.\]
\end{nota}

\begin{satz}[Mehrdimensionale Kettenregel]
	Seien $U \subset \mathbb R^l, V \subset \mathbb R^m, W \subset \mathbb R^n$ offene Mengen und $f\colon U\to V, g\colon V \to W$ differenzierbare Abbildungen. Dann ist auch $g\circ f\colon U \to W$ differenzierbar, und für die Differentiale gilt
	\[\DD(g\circ f)|_x = \DD g|_{f(x)} \circ \DD f|_x\]
	für $x \in U$. Für die partiellen Ableitungen der Komponenten gilt also
	\[\partial_i(g\circ f) = \sum_{j = 1}^m ((\partial_j g)\circ f) \cdot \partial_i f^j,\]
	d.\,h.
	\[(\partial_i(g\circ f))(x) = \sum_{j = 1}^m (\partial_j g)(f(x)) \cdot (\partial_i f^j)(x).\]
\end{satz}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Mannigfaltigkeiten}
	\section{Topologie}
		\begin{defn}[Topologischer Raum]
			Ein Tupel $(X,\mathcal{T})$ bestehend aus einer Menge $X$ und einer Familie von Teilmengen $\mathcal{T}$ heißt \emph{topologischer Raum}, wenn folgende Eigenschaften erfüllt sind:
			\begin{enumerate}[label=$T$\arabic*]
				\item $\emptyset, x\in \mathcal{T}$
				\item $\forall U_1, U_2\in \mathcal{T} \text{ gilt }U_1\cap U_2\in\mathcal{T}$
				\item Für jede Familie $\lbrace U_i\rbrace_{i\in I}\subset \mathcal{T}$ gilt $\bigcup_{i\in I}U_i\in\mathcal{T}$
			\end{enumerate}
			Die Familie $\mathcal{T}$ heißt \emph{Topologie} auf der Menge $X$, ihre Elemente heißen \emph{offene Mengen}. Eine Menge heißt \emph{abgeschlossen}, wenn ihr Komplement offen ist.
		\end{defn}
		\begin{defn}[Basis einer Topologie]
			Eine Familie offener Mengen $\lbrace B_i\rbrace_{i\in I}\subset \mathcal{T}$ heißt \emph{Basis} eines topologischen Raums $(X,\mathcal{T})$, wenn sich jede offene Menge als Vereinigung von Elementen der Basis schreiben lässt, das heißt:
			\begin{equation*}
				\forall U\in\mathcal{T}\exists \lbrace B_i\rbrace_{i\in J}\subset \mathcal{T}: U=\bigcup_{i\in J}B_i
			\end{equation*}
		\end{defn}
		\begin{bsp}
			Ist $(X,d)$ ein metrischer Raum, so bilden die bzgl. der Metrik offenen Mengen eine Topologie mit den $\varepsilon$-Bällen $\lbrace B_{\varepsilon}(x)\vert \; x\in X, \varepsilon >0\rbrace$ als Basis.
		\end{bsp}
		\begin{defn}[Zweitabzählbarkeit]
			Ein topologischer Raum $(X,\mathcal{T})$ heißt \emph{zweitabzählbar}, wenn für die Topologie $\mathcal{T}$ eine abzählbare Basis existiert. 
		\end{defn}
		\begin{defn}[Kompaktheit]
			Eine Teilmenge $K\subset X$ heißt \emph{kompakt}, wenn jede offene Überdeckung (das heißt jede Familie offener Mengen $\lbrace U_i\rbrace_{i\in I}$ mit $K\subset \bigcup_{i\in I}U_i$) eine endliche Teilüberdeckung hat (also endlich viele $U_1,\ldots,U_n$ existieren sodass schon $K\subset \bigcup_{i=1}^n U_i$ gilt).
		\end{defn}
		\begin{defn}[Hausdorffraum]
			Ein topologischer Raum $(X,\mathcal{T})$ heißt \emph{hausdorffsch} oder \emph{Hausdorffraum}, falls für je zwei Punkte $x,y\in X, x\neq y$ offene Umgebungen ${U_x,U_y\in\mathcal{T}}$, ${x\in U_x}, {y\in U_y}$ existieren sodass $U_x\cap U_y=\emptyset$. Zwei Punkte können also durch offene Mengen \glqq getrennt\grqq\ werden.
		\end{defn}
		\begin{lemma}
			In einem Hausdorffraum sind kompakte Mengen abgeschlossen.
		\end{lemma}
		\begin{bsp}
			Der euklidische Raum $(\R^n,d)$ ist mit der metrischen Topologie ein topologischer Raum. Er ist hausdorffsch und zweitabzählbar.
		\end{bsp}
		\begin{defn}[Stetige Abbildung]
			Eine Abbildung $f\colon (X,\mathcal{T}_X)\rightarrow (Y,\mathcal{T}_Y)$ zwischen topologischen Räumen heißt \emph{stetig}, wenn Urbilder offener Mengen offen sind:
			\begin{equation*}
				U\in\mathcal{T}_Y \Rightarrow f^{-1}(U)\in\mathcal{T}_X
			\end{equation*}
			Äquivalent dazu ist, dass Urbilder abgeschlossener Mengen abgeschlossen sind (da Komplementbildung mit dem Urbild vertauscht).
		\end{defn}
		Die Topologien werden im Folgenden in der Notation unterdrückt.
		\begin{lemma}
			Die Verkettung stetiger Abbildungen ist stetig.
		\end{lemma}
		\begin{lemma}
			Das Bild einer kompakten Menge unter einer stetigen Abbildung ist kompakt:
			\begin{equation*}
				f\colon X\rightarrow Y \text{ stetig }, K\subset X \text{ kompakt }\Rightarrow f(K)\subset Y \text{ kompakt}
			\end{equation*}
		\end{lemma}
		\begin{defn}[Homöomorphismus]
			Eine stetige Abbildung $f\colon X\rightarrow Y$ heißt \emph{Homöomorphismus}, wenn sie bijektiv und ihre Umkehrabbildung stetig ist.
		\end{defn}
	\section{Mannigfaltigkeiten}
		\begin{defn}
			Ein topologischer Raum $(M,\mathcal{T})$ heißt \emph{topologische Mannigfaltigkeit}, wenn er hausdorffsch, zweitabzählbar und lokal euklidisch ist, das heißt:
			Es existiert eine natürliche Zahl $n\in \mathbb{N}$ (Dimension), sodass für alle Punkte $x\in M$ offene Umgebungen $U\subset M, V\subset \R^n$ mit $x\in U $ und ein Homöomorphismus $ \varphi\colon U\rightarrow V$ existieren.

			Die Dimension der Mannigfaltigkeit ist wohldefiniert (Beachte, dass $n$ unabhängig von der Wahl des Punktes existieren muss).

			Das Tupel $(\varphi,U)$ heißt \emph{Karte} (wobei manchmal die Menge $U$ unterdrückt wird). Eine Familie von Karten, die die Mannigfaltigkeit überdecken, heißt \emph{Atlas} $\mathcal{A}$.
		\end{defn}
		\begin{bsp}\hfill 
			\begin{enumerate}
				\item Der euklidische Raum $\R^n$ ist eine $n$-dimensionale topologische Mannigfaltigkeit, beispielsweise mit dem Atlas $\lbrace (id_{\R^n},\R^n)\rbrace$. Ebenso gilt dies für beliebige offene Teilmengen.
				\item Das kartesische Produkt zweier topologischer Mannigfaltigkeiten (der Dimensionen $n$ und $m$) ist eine topologische Mannigfaltigkeit (der Dimension $n + m$). Die Produkte offener Mengen bilden dabei eine Basis der Topologie des Produktes.
				\item Für topologische Mannigfaltigkeiten gleicher Dimension ist die disjunkte Vereinigung eine topologische Mannigfaltigkeit (\emph{topologische Summe}).
			\end{enumerate}
		\end{bsp}
		\begin{defn}
			Für zwei Karten $\varphi_i\colon U_i\rightarrow V_i, i\in\lbrace 1,2 \rbrace$ heißt die folgende Abbildung \emph{Kartenwechsel}:
			\begin{equation*}
				\varphi_2\circ\varphi_1^{-1}\vert_{\varphi_1(U_1\cap U_2)}\colon \varphi_1(U_1\cap U_2)\rightarrow \varphi_2(U_1\cap U_2)
			\end{equation*}
			Da die Karten Homöomorphismen sind, sind auch alle Kartenwechsel Homöomorphismen.
		\end{defn} 
		\begin{defn}[Differenzierbare Mannigfaltigkeit]\hfill
			\begin{itemize}
				\item Zwei Karten heißen \emph{verträglich}, wenn ihr Kartenwechsel ein (glatter) Diffeomorphismus ist (das heißt, der Kartenwechsel und sein Inverses sind glatt).
				\item Ein Atlas heißt \emph{differenzierbar}, wenn alle seine Karten paarweise verträglich sind.
				\item Ein differenzierbarer Atlas heißt \emph{maximal}, wenn es keine Karte gibt, die mit allen Karten des Atlanten verträglich und nicht in ihm enthalten ist.
				\item Eine \emph{differenzierbare Struktur} auf einer topologischen Mannigfaltigkeit $M$ ist ein maximaler differenzierbarer Atlas $\mathcal{A}$ und das Tupel $(M,\mathcal{A})$ heißt \emph{differenzierbare Mannigfaltigkeit}. Wenn also von einer Karten auf einer differenzierbaren Mannigfaltigkeit die Rede ist, sind immer solche aus der differenzierbaren Struktur gemeint.
			\end{itemize}
		\end{defn}
		\begin{bsp}\hfill 
			\begin{enumerate}
				\item Der euklidische Raum $\R^n$ (und seine offenen Teilmengen) sind $n$-dimensionale differenzierbare Mannigfaltigkeiten, der oben genannte Atlas muss dazu aber erweitert werden! (Übung: Zeige allgemein, dass eine Vervollständigung eines nichtleeren Atlanten eindeutig ist)
				\kommP{Erwähnen, dass jeder dfb. Atlas einen eindeutige dfb. Struktur induziert, mit der er verträglich ist? Übungsaufgabe?}
				\item Reelle, endlich dimensionale Vektorräume sind differenzierbare Mannigfaltigkeiten.
				\item Die obigen Beispiele topologischer Mannigfaltigkeiten gelten auch für differenzierbare Mannigfalltigkeiten, allerdings müssen auch hier Atlanten vervollständigt werden.
				\item Die Sphären ${S^n:=\lbrace x\in\R^{n+1}\vert \|x\|=1\rbrace}$ sind differenzierbare Mannigfaltigkeiten, die sich nicht mit einer einzelnen Karte überdecken lassen.
			\end{enumerate}
		\end{bsp}
	\section{Differenzierbare Abbildungen}
		Seien von nun an $M,N$ differenzierbare Mannigfaltigkeiten.
		\begin{defn}[Differenzierbarkeit]
			Eine Abbildung $f\colon M\rightarrow N$ zwischen differenzierbaren Mannigfaltigkeiten heißt \emph{glatt}, wenn für alle Punkte $p\in M$ Karten $(\varphi,U)$ um  $p$ und $(\psi,V)$ um $f(p)$ existieren, sodass $f(U)\subset V$ und die folgende Abbildung glatt ist:
			\kommP{Evtl. $C^k$ definieren?}
			\begin{equation}
				\psi\circ f \circ \varphi^{-1}\colon \varphi(U)\rightarrow \psi(V)
			\end{equation}
			Diese Definition ist unabhängig von der Wahl der Karte, da Kartenwechsel glatt sind. Äquivalent kann daher auch gefordert werden, dass die obige Abbildung für alle Karten glatt ist.

			Wir schreiben $\sC(M,N)$ für die Menge der glatten Abbildungen.
		\end{defn}
		\begin{nota}
			$\sm(M):=\sC(M,\R)$ ist die Menge der (glatten) Funktionen auf $M$.
		\end{nota}
		\begin{defn}
			Eine Abbildung $f\in\sC(M,N)$ heißt Diffeomorphismus, wenn $f$ bijektiv ist und $f^{-1}\in\sC(N,M)$ gilt.

			Die Menge der Diffeomorphismen $\Diff(M)\subset\sC(M,M)$ bildet eine Gruppe.
		\end{defn}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Der Tangentialraum, das Differential, Untermannigfaltigkeiten}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Der Tangentialraum}
Idee: Was sind \glqq Richtungen\grqq\ auf einer Mannigfaltigkeit?

Anschaulich: Wenn Mf. eingebettet im $\mathbb R^n$, können wir uns eine Tangentialebene vorstellen (Bild: $S^2$ in $\mathbb R^3$). Also: Mögliche Richtungen = Ableitungen von Kurven. Aber abstrakt?

Müssen intrinsisch darüber reden können. Dabei hilft die Beobachtung, dass man Richtungen dazu benutzt, zu beschreiben, wie sich Dinge bei Bewegung in diese Richtung ändern. Also: Richtung = Richtungsableitung! \todo{Ableitung entlang von Kurven im $\mathbb R^n$ als Motivation.} Wir werden deshalb \glqq Richtungen\grqq\ als Ableitungsoperatoren formalisieren.

Idee: Ableitungen erfüllen eine Produktregel und wirken \glqq lokal\grqq.

Sei im Folgenden $M$ eine differenzierbare Mannigfaltigkeit, $\dim M = n$.

\begin{defn}[Funktionskeime]
	Sei $p \in M$. Auf der Menge $X = \{f \in \sC(U) : U \subset M \text{ offene Umgebung von } p\}$ betrachten wir die Äquivalenzrelation $\sim$, die gegeben ist durch
	\[f \sim g \diff \exists \text{ offene Umgebung } V \text{ von } p \text{ mit } f = g \text{ auf } V.\]
	Die Äquivalenzklassen bzgl. dieser Relation heißen glatte \emph{Funktionskeime} in $p$. Zwei um $p$ definierte Funktionen definieren also genau dann denselben Keim, wenn sie in einer Umgebung von $p$ übereinstimmen.

	Den Raum der Funktionskeime in $p$ schreiben wir als $\sC_p(M)$. Den Keim zu einer Funktion $f$ schreiben wir als $[f]$. Wenn keine Missverständnisse entstehen können, schreiben wir stattdessen manchmal auch $f$, um uns Notationsaufwand zu ersparen.
\end{defn}

Zu einem Funktionskeim $[f] \in \sC_p(M)$ ist der Funktionswert $[f](p) := f(p)$ wohldefiniert (warum?).

\begin{prop}
	\kommP{Das hab ich mal \glqq Proposition\grqq\ und nicht \glqq Lemma\grqq\ genannt, weil es nur im aktuellen Kontext relevant ist und man es außerhalb nicht braucht.}
	$\sC_p(M)$ ist mit über die Repräsentanten definierter Addition, Skalarmultiplikation und Multiplikation eine $\mathbb R$-Algebra.

	\begin{proof}
		Übung.
	\end{proof}
\end{prop}

\begin{defn}
	Eine \emph{Derivation} von $\sC_p(M)$ ist eine lineare Abbildung $v\colon \sC_p(M) \to \mathbb R$, die die \glqq Produktregel\grqq\ \[v(fg) = v(f) g(p) + f(p) v(g)\] erfüllt. Den Raum der Derivationen von $\sC_p(M)$ nennen wir den \emph{Tangentialraum} $T_pM$ an $M$ im Punkt $p$; die Elemente von $T_pM$ heißen auch \emph{Tangentialvektoren} in $p$.
\end{defn}

$T_pM$ ist tatsächlich ein Untervektorraum von $(\sC_p(M))^*$ (Übung).

\begin{lemma}[Derivationen verschwinden auf Konstanten]
	Für alle $v \in T_pM$ und $c \in \mathbb R$ ist $v(c) = 0$ (dabei fassen wir $c$ als konstante Funktion bzw. den davon induzierten Funktionskeim auf).
	
	\begin{proof}
		Es ist $v(1) = v(1\cdot 1) = v(1) 1(p) + 1(p) v(1) = 2 v(1)$, also $v(1) = 0$. Da $v$ linear ist, folgt die Behauptung.
	\end{proof}
\end{lemma}

\begin{bsp}
	Sei $\gamma\colon (-\varepsilon,\varepsilon) \to M$ eine glatte Kurve mit $\gamma(0) = p$. Wir definieren den Tangentialvektor $\gamma'(0) \in T_pM$ durch \[(\gamma'(0))(f) := (f\circ\gamma)'(0),\] wobei wir auf der rechten Seite die Ableitung der Funktion $f\circ\gamma \colon I \to \mathbb R, I \subset \mathbb R$ gebildet haben.

	$\gamma'(0)$ leitet also die Funktionskeime, auf die es angewendet wird, entlang der Kurve ab; wir können $\gamma'(0)$ also als \glqq Geschwindigkeitsvektor\grqq\ der Kurve auffassen. \kommB{Soll dazu noch eine konkrete Rechnung folgen? Vllt. als Übung? (Also dass man konkret im $\R^n$ nachrechnet, dass da so etwas wie eine Richtung herauskommt (unter Identifikation blabla)}

	$\gamma'(0)$ ist wohldefiniert und tatsächlich eine Derivation: Wenn $[f] = [g]$ gilt, dann stimmen $f$ und $g$ in einer Umgebung von $p$ überein, und damit stimmen $f\circ\gamma$ und $g\circ\gamma$ in einer Umgebung von $0$ überein und haben insbesondere dieselbe Ableitung an der Stelle $0$. Die Linearität von $\gamma'(0)$ folgt aus der Linearität der Ableitung, und die Derivations-Produktregel folgt aus der Produktregel für Ableitungen.
\end{bsp}

Später werden wir sehen, dass sich tatsächlich \emph{jeder} Tangentialvektor als Ableitung einer Kurve schreiben lässt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Das Differential}

Mithilfe des Tangentialraumbegriffs können wir nun nicht nur entscheiden, ob Abbildungen differenzierbar sind, sondern auch tatsächlich eine Art Ableitungsbegriff definieren:
\begin{defn}
	Seien $M,N$ differenzierbare Mannigfaltigkeiten und $f\colon M \to N$ eine differenzierbare Abbildung. Das \emph{Differential} von $f$ im Punkt $p\in M$ ist die lineare Abbildung
	\[\DD f|_p \colon T_pM \to T_{f(p)}N\]
	definiert durch
	\[(\DD f|_p(v))(\alpha) = v (\alpha\circ f)\]
	für $v\in T_pM, \alpha \in \sC_{f(p)}(N)$.
\end{defn}
\begin{prop}
	$\DD f|_p(v)$ ist tatsächlich wohldefiniert und eine Derivation von $\sC_{f(p)}(N)$, und $\DD f|_p$ ist linear.

	\begin{proof}
		Übung.
	\end{proof}
\end{prop}

\begin{satz}[Kettenregel]
	Seien $f\colon M \to N, g\colon N \to L$ glatte Abbildungen zwischen differenzierbaren Mannigfaltigkeiten, und $p \in M$. Dann gilt \[\DD(g\circ f)|_p = \DD g|_{f(p)} \circ \DD f|_p.\]

	\begin{proof}
		Sei $v \in T_pM$. Für jedes $\alpha \in \sC_{g(f(p))}(L)$ ist $(\DD(g\circ f)|_p(v))(\alpha) = v(\alpha\circ (g \circ f)) = v((\alpha\circ g) \circ f) = (\DD f|_p(v)) (\alpha \circ g) = (\DD g|_{f(p)}(\DD f|_p(v))) (\alpha)$, also gilt $\DD(g\circ f)|_p(v) = \DD g|_{f(p)}(\DD f|_p(v))$.
	\end{proof}
\end{satz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Koordinatenvektoren}

Haben wir eine Karte gegeben, dann gibt sie uns spezielle \glqq Richtungen, in die wir ableiten können\grqq:
\begin{defn}
	Sei $(\varphi,U)$ eine Karte um $p$. Für $i = 1,\dots, n$ definieren wir den Tangentialvektor $\left.\frac{\partial}{\partial x^i}\right|_p \in T_pM$ durch
	\[\left.\frac{\partial}{\partial x^i}\right|_p(f) := \left(\partial_i \left(f\circ \varphi^{-1}\right)\right) (\varphi(p)).\]
	Die $\left.\frac{\partial}{\partial x^i}\right|_p$ heißen die von $\varphi$ \emph{induzierten Koordinatenvektoren} in $p$.
\end{defn}
$\left.\frac{\partial}{\partial x^i}\right|_p$ stellt also einen Funktionskeim in der Karte $\varphi$ dar und bildet die $i$-te partielle Ableitung dieser Kartendarstellung. (Achtung: Notation ist schlecht, die Vektoren hängen natürlich von der Wahl von $\varphi$ ab!)
\begin{prop}
	$\left.\frac{\partial}{\partial x^i}\right|_p$ ist tatsächlich eine Derivation von $\sC_p(M)$.

	\begin{proof}
		$\left.\frac{\partial}{\partial x^i}\right|_p$ ist wohldefiniert, denn wenn $[f] = [g]$ gilt, dann stimmen $f$ und $g$ in einer Umgebung von $p$ überein, und damit stimmen $f\circ \varphi^{-1}$ und $g\circ \varphi^{-1}$ in einer Umgebung von $\varphi(p)$ überein und haben insbesondere dieselben Ableitungen an der Stelle $\varphi(p)$.

		Die Linearität von $\left.\frac{\partial}{\partial x^i}\right|_p$ folgt direkt aus der Linearität von partiellen Ableitungen. Dass $\left.\frac{\partial}{\partial x^i}\right|_p$ eine Derivation ist, folgt aus der Produktregel für partielle Ableitungen:
		\begin{align*}
			\left.\frac{\partial}{\partial x^i}\right|_p (fg) &= \left(\partial_i \left((fg)\circ \varphi^{-1}\right)\right) (\varphi(p))\\
			&= \left(\partial_i \left( \left(f\circ \varphi^{-1}\right) \cdot \left(g\circ \varphi^{-1}\right) \right) \right) (\varphi(p))\\
			&= \left(\partial_i \left(f\circ \varphi^{-1}\right) \right)(\varphi(p)) \cdot \left(g\circ \varphi^{-1}\right) (\varphi(p)) \\&\quad+ \left(f\circ \varphi^{-1}\right) (\varphi(p)) \cdot \left(\partial_i \left(g\circ \varphi^{-1}\right) \right)(\varphi(p))\\
			&= \left.\frac{\partial}{\partial x^i}\right|_p (f) \cdot g(p) + f(p) \cdot \left.\frac{\partial}{\partial x^i}\right|_p (g) \qedhere
		\end{align*}
	\end{proof}
\end{prop}

\begin{lemma}
	Für eine Karte $(\varphi,U)$ um $p$ sind die Komponenten $\varphi^i, i = 1,\dots, n$ reellwertige glatte Funktionen auf $U$, können also als Funktionskeime in $p$ aufgefasst werden. Wendet man darauf die Koordinatenvektoren an, so erhält man \[\left.\frac{\partial}{\partial x^i}\right|_p (\varphi^j) = \delta^j_i.\]
	\begin{proof}
		Es ist
		\begin{align*}
			\left.\frac{\partial}{\partial x^i}\right|_p (\varphi^j) &= \left(\partial_i \left(\varphi^j\circ \varphi^{-1}\right)\right) (\varphi(p))\\
			&= \underbrace{\left(\partial_i \pr^j\right)}_{= \delta^j_i} (\varphi(p)) = \delta^j_i,
		\end{align*}
		wobei $\pr^j\colon \mathbb R^n \to \R, \pr^j(x) = x^j$ die Projektion auf die $j$-te Komponente ist.
	\end{proof}
\end{lemma}

Wir wollen jetzt zeigen, dass die $\left.\frac{\partial}{\partial x^i}\right|_p, i = 1,\dots,n$ eine Basis von $T_pM$ bilden, dass also der Begriff von Derivationen tatsächlich eine gewisse Art von Intuition über \glqq Richtungen\grqq\ erfüllt ($n$ verschiedene Richtungen, Ableitung nach verschiedenen Koordinaten entspricht unabhängigen Richtungen):
\begin{satz} \label{satz:koord_basis}
	Sei $\varphi$ eine Karte um $p$. Die induzierten Koordinatenvektoren $\left.\frac{\partial}{\partial x^1}\right|_p, \dots, \left.\frac{\partial}{\partial x^n}\right|_p$ bilden eine Basis von $T_pM$.

	\begin{proof}\let\qed\relax
		Lineare Unabhängigkeit zu zeigen ist einfach: Aus $\sum_{i=1}^n \lambda^i \left.\frac{\partial}{\partial x^i}\right|_p = 0$ folgt mit dem obigen Beispiel $0 = \sum_{i=1}^n \lambda^i \left.\frac{\partial}{\partial x^i}\right|_p (\varphi^j) = \sum_{i=1}^n \lambda^i \delta^j_i = \lambda^j$ für alle $j = 1,\dots, n$. Um zu zeigen, dass die Vektoren auch ein Erzeugendensystem bilden, brauchen wir einen kleinen Trick.
	\end{proof}
\end{satz}

\begin{lemma}[Hadamard-Lemma] \label{lemma:Hadamard}
	Seien $U \subset \mathbb R^n$ eine offene Menge, die sternförmig um $x_0$ ist, und $f \in \sC(U)$. Dann gibt es glatte Funktionen $f_i \in \sC(U), i = 1,\dots,n$, sodass \[f(x) = f(x_0) + \sum_{i=1}^n f_i(x) (x^i - x_0^i).\]

	\begin{proof}
		Für $x \in U$ setze $y := x - x_0$. Dann ist
		\begin{align*}
			f(x) - f(x_0) &= f(x_0 + 1\cdot y) - f(x_0 + 0\cdot y)\\
			&= \int_0^1 \left(\frac{\D}{\D t} f(x_0 + ty)\right) \D t\\
			\text{(Kettenregel)} \quad &= \int_0^1 \sum_{i=1}^n (\partial_i f)(x_0 + ty) y^i \D t\\
			&= \sum_{i=1}^n \left(\int_0^1 (\partial_i f)(x_0 + tx - tx_0) \D t\right) (x^i - x_0^i).
		\end{align*}
		Mit \[f_i(x) := \int_0^1 (\partial_i f)(x_0 + tx - tx_0) \D t\] folgt also die Behauptung (die $f_i$ sind glatt wegen Kettenregel und Sätzen über das Differenzieren unter dem Integral).
	\end{proof}
\end{lemma}

\begin{kor}[Hadamard-Lemma auf Mannigfaltigkeiten]
	Seien $p\in M$, $\alpha \in \sC_p(M)$ und $(\varphi,U)$ eine Karte um $p$. Dann gibt es $\alpha_i \in \sC_p(M), i = 1,\dots, n$ mit \[\alpha = \alpha(p) + \sum_{i=1}^n \alpha_i \cdot (\varphi^i - \varphi^i(p)).\]

	\begin{proof}
		Sei $f\colon V \to \mathbb R$ ein Repräsentant von $\alpha$, sodass $V \subset U$ eine solche Menge ist, dass $W := \varphi(V) \subset \mathbb R^n$ sternförmig um $\varphi(p)$ ist (z.\,B. könnte $W$ eine kleine offene Kugel sein). Dann ist $f\circ\varphi^{-1}|_W \in \sC(W)$. Nach dem Hadamard-Lemma \ref{lemma:Hadamard} gibt es also glatte Funktionen $g_i$ auf $W$ mit $f(\varphi^{-1}(x)) = f(p) + \sum_{i=1}^n g_i(x) (x^i - \varphi^i(p))$. Für alle $q \in V$ ist damit $f(q) = f(p) + \sum_{i=1}^n g_i(\varphi(q)) \cdot (\varphi^i(q) - \varphi^i(p))$, die Behauptung folgt also mit $\alpha_i := [g_i \circ \varphi]$.
	\end{proof}
\end{kor}

\begin{proof}[Zurück zum Beweis von Satz \ref{satz:koord_basis}]
	Mit dem Hadamard-Lemma können wir jetzt auch zeigen, dass die Koordinatenvektoren ein Erzeugendensystem bilden. Seien $v \in T_pM$ und $\alpha \in \sC_p(M)$ beliebig, und seien $\alpha_i \in \sC_p(M)$ zu $\alpha$ mit dem Hadamard-Lemma gewählt. Dann ist
	\begin{align}\begin{split} \label{eq:pf_koord_basis}
		v(\alpha) &= v\left(\alpha(p) + \sum_{i=1}^n \alpha_i \cdot (\varphi^i - \varphi^i(p))\right)\\
		\text{(Linearität, $v(\text{const.}) = 0$)} \quad &= \sum_{i=1}^n v(\alpha_i \cdot (\varphi^i - \varphi^i(p)))\\
		&= \sum_{i=1}^n \left( v(\alpha_i) \cdot (\varphi^i(p) - \varphi^i(p)) + \alpha_i(p) \cdot v(\varphi^i) \right)\\
		&= \sum_{i=1}^n \alpha_i(p) \cdot v(\varphi^i).
	\end{split}\end{align}
	Insbesondere gilt damit auch $\left.\frac{\partial}{\partial x^i}\right|_p (\alpha) = \sum_{j=1}^n \alpha_j(p) \cdot \delta^j_i = \alpha_i(p)$. Zurückeingesetzt in \eqref{eq:pf_koord_basis} erhalten wir damit
	\begin{equation*}
		v(\alpha) = \sum_{i=1}^n \left.\frac{\partial}{\partial x^i}\right|_p (\alpha) \cdot v(\varphi^i)
		= \left(\sum_{i=1}^n v(\varphi^i) \left.\frac{\partial}{\partial x^i}\right|_p \right)(\alpha)
	\end{equation*}
	Da $\alpha$ beliebig war, gilt also $v = \sum_{i=1}^n v(\varphi^i) \left.\frac{\partial}{\partial x^i}\right|_p$. Wir können also jedes $v \in T_pM$ als Linearkombination der Koordinatenvektoren schreiben.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Vektorbündel}
	\section{Faserbündel}
		\begin{defn}[Faserbündel]
			Ein \emph{Faserbündel} $(P,M,\pi ,F)$ ist ein Tupel aus drei Mannigfaltigkeiten (dem \emph{Totalraum} $P$, der \emph{Basis} $M$ und der \emph{typischen Faser} $F$) zusammen mit einer surjektiven \emph{Projektion} $\pi\colon P\rightarrow M$, die die folgenden Eigenschaften erfüllt:

				Für alle Punkte $x\in M$ existieren eine offene Umgebung $x\in U\subset M$ und ein Diffeomorphismus $\phi\colon \pi^{-1}(U)\rightarrow U\times F$, sodass das folgende Diagramm kommutiert, also $\pi\vert_{\pi^{-1}(U)}=\pr_1\circ\phi$ (wobei $\pr_1$ die Projektion auf den ersten Faktor bezeichnet):
			\begin{center}
			\begin{tikzpicture}
				\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{\pi^{-1}(U) & U\times F \\
     U& \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$\phi$} (m-1-2)
  							edge node [left]{$\pi$} (m-2-1)
  					(m-1-2) edge node [below]{$\quad\pr_1$} (m-2-1)
  					;
			\end{tikzpicture}
			\end{center}
			Eine solche Abbildung $\phi$ heißt \emph{lokale Trivialisierung}. Aufgrund der Existenz lokaler Trivialisierungen ist das Urbild jedes Punktes $x\in M$ unter der Projektion (\emph{Faser} von $x$ genannt) $P_x:=\pi^{-1}(\lbrace x\rbrace )$ diffeomorph zur typischen Faser: $P_x\cong F \; \forall x\in M$.

			Eine Familie lokaler Trivialisierungen, die $P$ überdecken, heißt \emph{Bündelatlas}.
		\end{defn}
		\begin{nota}
			Man sagt auch \glqq Faserbündel über $M$\grqq und schreibt dafür einfach $(P,\pi)$.
		\end{nota}
		Sei von nun an $(P,M,\pi ,F)$ ein Faserbündel.
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Das triviale Bündel mit typischer Faser $F$ und Basis $M$ ist das kartesische Produkt $M\times F$ (genauer gesagt das Bündel $(M\times F,\pr_1))$.
				\item Für eine offene Menge $U\subset M$ und $P\vert_U:=\pi^{-1}(U)$ ist $(P\vert_U,U,\pi\vert_{P_U},F)$ ein Faserbündel.
			\end{enumerate}
		\end{bsp}
		\begin{defn}[Schnitt]
			Eine Abbildung $\sigma\colon M\rightarrow P$ heißt (globaler) \emph{Schnitt}, wenn $\pi\circ\sigma=\id_M$, also $\sigma(x)\in P_x\, \forall x\in M$. Analog heißt für eine offene Menge $U\subset M$ eine Abbildung $\sigma\colon U\rightarrow P\vert_U$ \emph{lokaler Schnitt}, wenn $\pi\circ\sigma=\id_U$.

			Die Menge aller globalen Schnitte wird mit $\Gamma(P)$ bezeichnet, die der lokalen Schnitte mit $\Gamma(P\vert_U)$.
		\end{defn}
	\section{Vektorbündel}
		\begin{defn}[Vektorbündel]
				Ein Faserbündel $(E,M,\pi,\R^n)$ heißt \emph{Vektorbündel} vom \emph{Rang} $n$, wenn $E_x$ für alle Punkte $x\in M$ ein $n$-dimensionaler Vektorraum ist. Weiter soll es einen Bündelatlas aus lokalen Trivialisierungen ${\phi\colon \pi^{-1}(U)\rightarrow U\times \R^n}$ geben, sodass die folgende Abbildung für jeden Punkt $x\in U$ ein Vektorraumisomorphismus ist:
				\begin{equation*}
					E_x\rightarrow \R^n,\; p\mapsto \pr_2(\phi(p))
				\end{equation*}
			Daraus folgt, dass die Abbildung ${\R^n\rightarrow E_x,\; v\mapsto \phi^{-1}(x,v)}$ ebenfalls ein Vektorraumisomorphismus ist.
		\end{defn}
		Analog zu Kartenwechseln lassen sich auch \emph{Trivialisierungswechsel} definieren:
		\begin{defn}
			Sei $(E,M,\pi,\R^n)$ ein Vektorbündel, $U,V\subset M$ mit $U\cap V\neq\emptyset$ und Trivialisierungen ${\phi_U\colon \pi^{-1}(U)\rightarrow U\times \R^n}, {\phi_V\colon \pi^{-1}(U)\rightarrow U\times \R^n}$.

			Die folgende Abbildung heißt \emph{Trivialisierungswechsel}:
			\begin{equation*}
				\phi_V\circ\phi_U^{-1}\colon (U\cap V)\times \R^n\rightarrow (U\cap V)\times \R^n, (q,v)\mapsto (q,\tau(q)v)
			\end{equation*}
			wobei die Einschränkung unterdrückt wurde. Die Abbildung $\tau\colon U\cap V\rightarrow \GL(n,\R)$ ist glatt und wird als \emph{Übergangsfunktion} bezeichnet.
		\end{defn}
		\begin{defn}[Vektorbündelhomomorphismen]\hfill\\
			Seien $(E_a,M_a,\pi_a,\R^{n_a}),(E_b,M_b,\pi_b,\R^{n_b})$ Vektorbündel.
			
			Ein Tupel $(F,f)$ mit $F\colon E_a\rightarrow E_b$ und $f\colon M_a\rightarrow M_b$ heißt \emph{Vektorbündelhomomorphismus}, wenn das folgende Diagramm kommutiert:
			\begin{center}
				\begin{tikzpicture}
					\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{E_a & E_b \\
     M_a&M_b \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$F$} (m-1-2)
  							edge node [left]{$\pi_a$} (m-2-1)
  					(m-1-2) edge node [right]{$\pi_b$} (m-2-2)
  					(m-2-1) edge node [above]{$f$} (m-2-2)
  					;
				\end{tikzpicture}
			\end{center}
			also $\pi_b\circ F=f\circ\pi_a$.
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Das triviale Bündel $M\times \R^n$ ist ein Vektorbündel vom Rang $n$.
				\item Das Tangentialbündel $TM:=\bigcup_{x\in M}T_xM$ ist ein Vektorbündel vom Rang $n:=\dim M$. Beachte jedoch, dass im Allgemeinen $TM\ncong M\times \R^n$ (es existiert also nicht unbedingt ein Vektorbündelisomorphismus zwischen dem Tangential- und dem trivialen Bündel). Im Fall $TM\cong M\times \R^n$ heißt die Mannigfaltigkeit parallelisierbar.
			\end{enumerate}
		\end{bsp}
	\section{Konstruktionen von Vektorbündeln}
		Seien $(E_a,M,\pi_a,\R^{n_a}),(E_b,M,\pi_b,\R^{n_b})$ Vektorbündel.\\
		\begin{defn}
			Das zu $(E,M,\pi,\R^{n})$ \emph{duale Bündel} $(E^*,M,\pi^{\prime},(\R^n)^*)$ ist gegeben durch
			\begin{align*}
				E^*&:=\bigcup_{x\in M}(E_{x})^*\\
				\pi^{\prime}&\colon E^*\rightarrow M\\
				(\pi^{\prime})^{-1}(x)&=E^*_x=(E_{x})^*\quad \forall x\in M
			\end{align*}
			und für eine Trivialisierung $(\phi,U)$ von $E$, ist die folgende Abbildung eine Trivialisierung des dualen Bündels:
			\begin{align*}
				\phi^{\prime}\colon(\pi^{\prime})^{-1}(U)&\rightarrow U\times (\R^n)^*\\
				\lambda&\mapsto\left(x,\lambda\circ(\pr_2\circ\phi\vert_{\pi^{-1}(\lbrace x\rbrace)})^{-1}\right)
			\end{align*}
			wobei $\lambda\in E_x^*$. Trivialisierungswechsel sind (unter Identifikation von $\R^n$ mit Spalten- und $(\R^n)^*$ mit Zeilenvektoren) durch $\tau^{\prime}=\tau^{-1}$ gegeben, sodass $(x,\lambda)\mapsto(x,\lambda\tau^{\prime}(x))$.
		\end{defn}
		\begin{bsp}
			Mit obiger Konstruktion können wir aus dem Tangentialbündel $TM$ das \emph{Kotangentialbündel} $T^*M$ gewinnen. Wie wir später sehen werden, ergeben sich in Kombination mit den folgenden Konstruktionen viele neue Strukturen.
		\end{bsp}
		\begin{defn}[Whitney-Summe]
			Die \emph{Whitney-Summe} $(E_a\oplus E_b ,M,\pi,\R^{n_a+n_b})$ ist ein Vektorbündel gegeben durch
			\begin{align*}
				E_a\oplus E_b&:=\bigcup_{x\in M}E_{a,x}\oplus E_{b,x}\\
				\pi&\colon E_a\oplus E_b\rightarrow M\\
				(\pi)^{-1}(x)&=(E_a\oplus E_b)_x=E_{a,x}\oplus E_{b,x}\quad \forall x\in M
			\end{align*}
			und für Trivialisierungen $(\phi_a,U),(\phi_b,U)$ ist die folgende Abbildung eine Trivialisierung der Whitney-Summe:
			\begin{align*}
				\phi\colon\pi^{-1}(U)&\rightarrow U\times \R^{n_a+n_b}\\
				v_a\oplus v_b&\mapsto (\pi_a(v_a), \pr_2(\phi_a(v_a))\oplus\pr_2(\phi_b(v_b)))
			\end{align*}
			Trivialisierungswechsel sind (wieder unter Verwendung von Spaltenvektoren) durch die folgende Blockdiagonalmatrix gegeben: 
			\begin{equation}
				\tau=\left(\begin{array}{cc}\tau_a&0\\0&\tau_b\\ \end{array}\right)
			\end{equation}
		\end{defn}
		\begin{defn}[Tensorprodukt]
			Das \emph{Tensorprodukt} $(E_a\otimes E_b ,M,\pi,\R^{n_a\cdot n_b})$ von Vektorbündeln ist ein Vektorbündel gegeben durch
			\begin{align*}
				E_a\otimes E_b&:=\bigcup_{x\in M}E_{a,x}\otimes E_{b,x}\\
				\pi&\colon E_a\otimes E_b\rightarrow M\\
				(\pi)^{-1}(x)&=(E_a\otimes E_b)_x=E_{a,x}\otimes E_{b,x}\quad \forall x\in M
			\end{align*}
			und für Trivialisierungen $(\phi_a,U),(\phi_b,U)$ ist die folgende Abbildung eine Trivialisierung des Tensorprodukts:
			\begin{align*}
				\phi_a\otimes\phi_b\colon\pi^{-1}(U)&\rightarrow U\times \R^{n_a\cdot n_b}\\
				v_a\otimes v_b&\mapsto (\pi_a(v_a), \pr_2(\phi_a(v_a))\otimes\pr_2(\phi_b(v_b)))
			\end{align*}
			Die Übergangsfunktionen des Tensorproduktes sind durch das Tensorprodukt der Übergangsfunktionen gegeben: $\tau=\tau_a\otimes\tau_b$.
		\end{defn}
		\todo{Tensorprodukt von VR}
		
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Vektorfelder}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Lie-Gruppen}
	\section{Grundlagen}
		\begin{defn}[Lie-Gruppe]
			Eine \emph{Lie-Gruppe} ist eine differenzierbare Mannigfaltigkeit $G$ mit einer Gruppenstruktur, sodass die Verknüpfung $\cdot\colon G\times G\rightarrow G, (g,h)\mapsto g\cdot h$ und die Inversion ${i\colon G\rightarrow G}, {g\mapsto g^{-1}}$ glatte Abbildungen sind.
			
			Wir definieren die \emph{Linkstranslation} entlang $g$:
			\begin{equation}
				l_g\colon G\to G, h\mapsto g\cdot h
			\end{equation}
			
			Es gelten $(l_g)^{-1}=l_{g^{-1}}$ und $l_g\circ l_h=l_{g\cdot h}$, also ist $l\colon G\rightarrow \mathrm{Aut}(G)$ ein Gruppenhomomorphismus.
			
			Analog lassen sich auch die \emph{Rechtstranslation} $r_g$ (mit $r_g\circ r_h=r_{h\cdot g}$) und die \emph{Konjugation} $c_g:= r_{g^{-1}}\circ l_g$ definieren. Rechts- und Linkstranslationen kommutieren und sind (Anti-) Automorphismen der Lie-Gruppe.
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item $\R^n$ ist zusammen mit der Addition von Vektoren eine Lie-Gruppe.
				\item $\GL(V)$ ist für $n=\dim_{\R} V$ eine $n^2$-dimensionale und $\mathrm{SL}(n,\R)$ eine $(n^2-1)$-dimensionale Lie-Gruppe (Die komplexen Versionen haben die doppelte Dimension). Weitere Beispiele sind die orthogonalen und unitären Gruppen $\mathrm{O}(n)$ ($n(n-1)/2$-dimensional), $\mathrm{SO}(n)$ ($n(n-1)/2$), $\mathrm{U}(n)$ ($n^2$) und $\mathrm{SU}(n)$ ($n^2-1$).
				\item $S^1\cong \lbrace z\in \mathbb{C}\vert zz^*=1\rbrace$ bekommt durch die Multiplikation in der komplexen Ebene eine Gruppenstruktur und ist damit eine Lie-Gruppe (nämlich gerade $\mathrm{U}(1)$). 
			\end{enumerate}
			
		\end{bsp}
		Sei $G$ von nun an eine Lie-Gruppe mit neutralem Element $e$.
		\begin{defn}[Linksinvariante Vektorfelder]
			Ein \emph{linksinvariantes Vektorfeld} ist ein Vektorfeld $X\in\mathfrak{X}(G)$, das \glqq invariant\grqq\ unter dem push-forward von Linkstranslationen ist. Das heißt, dass folgende Gleichung gilt:
			\begin{equation*}
				\left((l_g)_*X\right)_h\stackrel{\text{Def.}}{=}\DD l_g\vert_{g^{-1}\cdot h}X_{g^{-1}\cdot h}=X_h
			\end{equation*}
			Die Menge der linksinvarianten Vektorfelder heißt $\vf^L(G)$.
		\end{defn}
		\begin{satz}
			Die linksinvarianten Vektorfelder bilden eine endlich-dimensionale Unteralgebra der Algebra der Vektorfelder (mit dem Kommutator als Verknüpfung).
			
			Sie ist als Vektorraum isomorph zum Tangentialraum des neutralen Elements $T_eG$.
			\begin{proof}
				Zum Beweis konstruieren wir den kanonischen Isomorphismus und zeigen, dass die linksinvarianten Vektorfelder unter Bildung von Kommutatoren abgeschlossen sind:
				\begin{align}
					\Psi&\colon\vf^L(G)\to T_eG, X\mapsto X_e\nonumber\\
					L&\colon T_eG\rightarrow \vf^L(G), v\mapsto (g\mapsto \DD l_g\vert_e v)\label{def:kan_Iso}
				\end{align}\kommB{Ist $L$ ein guter Name bzw. gibt es da einen üblichen?}
				$L$ ist wohldefiniert, denn für $v\in T_eG$ und $g,h\in G$ gilt:
				\begin{align*}
					\left((l_g)_*L(v)\right)_h&=\DD l_g\vert_{g^{-1}\cdot h}L(v)_{g^{-1}\cdot h}\\
					&=\DD l_g\vert_{g^{-1}\cdot h}\DD (l_{g^{-1}\cdot h}\vert_e v)\\
					\text{(Kettenregel)}\quad &=\DD\left(l_g\circ l_{g^{-1}}\right)\big\vert _h\DD l_h\vert_e v\\
					&=\DD l_h\vert_e v\\
					&=L(v)_h
				\end{align*}
				Außerdem gilt $\Psi\circ L=\id_{T_eG}$:
				\begin{align*}
					\Psi(L(v))= (g\mapsto \DD l_g\vert_e v)_e=\DD l_e\vert_e v=v
				\end{align*}
				und die Umkehrung $L(\Psi(X))=X$ wird punktweise durch Ausnutzen der Linksinvarianz klar:
				\begin{align*}
					X_g&=\DD l_g\vert_{g^{-1}\cdot g}X_{g^{-1}\cdot g}=\left((l_g)_*X\right)_g\\
					&=\DD l_g\vert_e X_e\\
					&=L(X_e)_g
				\end{align*}
				Beide Abbildungen sind linear, für $L$ gilt dies, da das Differential linear ist.
				
				Nun bleibt zu zeigen, dass der Kommutator zweier linksinvarianter Vektorfelder linksinvariant ist (Übung).
			\end{proof}
		\end{satz}
		\begin{defn}[Lie-Algebra]
			Die \emph{Lie-Algebra} einer Lie-Gruppe ist der Vektorraum $\mathfrak{g}:=T_eG$ mit der folgenden Verknüpfung:
			\begin{align*}
				\left[.,.\right]\mathfrak{g}\times \mathfrak{g}\rightarrow \mathfrak{g}, (v,w)\mapsto \left[v,w\right]:=\left[L(v),L(w)\right]_e
			\end{align*}
			mit dem kanonischen Isomorphismus $L\colon \mathfrak{g}\to \vf^L(G)$ aus Gleichung (\ref{def:kan_Iso}). Diese Verkettung ist bilinear und antisymmetrisch nach Konstruktion.
		\end{defn}
		\begin{bsp}\hfill
			Die Lie-Algebra der $\GL(V)$ ist der Vektorraum der Endomorphismen $\End(V)$. Dies wird klar, wenn man $\GL(n,\R)$ als (offene) Teilmenge des $\R^{n^2}$ betrachtet: Der Tangentialraum ist dann kanonisch $\R^{n^2}\cong\End(\R^n)$ und durch Basiswahl erhält man die Identifizierung für beliebige (reelle) Vektorräume.
		\end{bsp}
		\begin{lemma}
			Linksinvariante Vektorfelder sind vollständig, das heißt, ihre Integralkurven können auf ganz $\R$ fortgesetzt werden.
			\begin{proof}
				$\gamma_g\colon I_g\rightarrow G$ Integralkurve in $g\in G$ $\Rightarrow \gamma^{\prime}\colon I_g\rightarrow G, t\mapsto l_h(\gamma_g(t))$ ist Integralkurve in $h\cdot g\;\forall h\in\gamma_g(I_g)$ (Kettenregel) $\rightarrow$ Setze $\gamma_g$ fort.
			\end{proof}\todo{Ausformulieren mit Notation des vorherigen Kapitels}
		\end{lemma}
	\section{Die Exponentialabbildung}
		\begin{defn}[Exponentialabbildung]
			Die \emph{Exponentialabbildung} $\exp\colon\mathfrak{g}\rightarrow G$ ist durch den Fluss der linksinvarianten Vektorfelder definiert:
			\begin{equation*}
				\exp(v):=\Phi_1^{L(v)}(e)
			\end{equation*}\kommB{Notation des vorherigen Kapitels übernehmen!}
			Dies entspricht gerade der Integralkurve von $L(v)$ in $e$ ausgewertet an der Stelle $1$.
		\end{defn}
		\begin{lemma}\label{lemma:Eigenschaften_exp}
			Die Exponentialabbildung besitzt die folgenden Eigenschaften:
			\begin{enumerate}[label=\arabic*]
				\item $\frac{d}{dt}\exp(tv)\Big\vert_{t=0}=v\quad\forall v\in\mathfrak{g}$
				\item $\exp(0)=e$
				\item $\exp((s+t)v)=\exp(sv)\cdot\exp(tv) \quad\forall v\in\mathfrak{g}, s,t\in \R$
			\end{enumerate}
			\begin{proof}
				Übung. (Für die dritte Eigenschaft, konstruiere zwei Integralkurven in $\exp(sv)$) \kommB{Hinweis: Zum Beweis der dritten Eigenschaft hilft der Beweis der Vollständigkeit von linksinvarianten Vektorfeldern und die Eigenschaften von Integralkurven bzgl. Skalierung.}
			\end{proof}
		\end{lemma}
		\begin{lemma}[Fluss linksinvarianter Vektorfelder]\label{lemma:Fluss_linksinvarianter_Vektorfelder}
			Sei $X\in\vf^L(G)$.
			
			Der Fluss von $X$ ist durch die Exponentialabbilding wie folgt gegeben:
			\begin{align*}
				\Phi^X_t(p)=p\cdot \exp(tX_e) \; =l_p(\exp(tX_e))=r_{\exp(tX_e)}(p)
			\end{align*}
			\begin{proof}
				Es gilt $l_p(\exp(0))=p=\Phi^X_0(p)$. Wir zeigen nun, dass $l_p(\exp(tX_e)$ $X$ erzeugt und die Aussage folgt dann aufgrund der Eindeutigkeit der Lösung von Differentialgleichungen (oder von Integralkurven).
				\begin{align*}
					\frac{d}{dt}l_p(\exp(tX_e))&=\frac{d}{ds}l_{p\cdot\exp(tX_e)}(\exp(sX_e))\Big\vert_{s=0}\\
					&=\DD l_{p\cdot\exp(tX_e)}\vert_eX_e\\
					&=X_{p\cdot\exp(tX_e)}
				\end{align*}
			\end{proof}
		\end{lemma}
		\begin{lemma}
			Für einen Lie-Gruppenhomomorphismus $\phi\colon G\rightarrow H$ (einen glatten Gruppenhomomorphismus zwischen Lie-Gruppen) kommutiert das folgende Diagramm:
			\begin{center}
			\begin{tikzpicture}
				\matrix(m)[matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]{\mathfrak{g} & \mathfrak{h} \\
     G&H \\};
  				\path[-stealth]
  					(m-1-1)	edge node [above]{$\DD\phi\vert_e$} (m-1-2)
  							edge node [left]{$\exp$} (m-2-1)
  					(m-1-2) edge node [right]{$\exp$} (m-2-2)
  					(m-2-1) edge node [above]{$\phi$} (m-2-2)
  					;
			\end{tikzpicture}
			\end{center}
			Man kann zeigen, dass die Abbildung $\DD\phi\vert_e$ ein Lie-Algebrenhomomorphismus ist, also mit den Kommutatoren verträglich ist.
			\begin{proof}
				Wir wollen zeigen, dass $\exp(D\phi\vert_e v)=\phi(\exp(v))\forall v\in\mathfrak{g}$ gilt. Sei $v\in\mathfrak{g}$, ${\gamma\colon [0,1]\rightarrow G}$,$ \gamma(t):=\phi(\exp(tv))$ und zeige nun, dass $\gamma$ die Integralkurve von $L(\DD\phi\vert_e v)$ in $e\in H$ ist:
				\begin{align*}
					\gamma'(t)&=\frac{d}{dt}(\phi(\exp(tv))\\
					&=\DD\phi\vert_{\exp(tv)}\DD l_{\exp(tv)}\vert_e v\\
					&=\DD(\phi\circ l_{\exp(tv)})\vert_e v\\
					&=\DD(l_{\phi(\exp(tv))}\circ\phi)\vert_e v\\
					&=\DD l_{\gamma(t)}\vert_e\DD\phi\vert_ev\\
					&=L(\DD\phi\vert_e v)_{\gamma(t)}
				\end{align*}
				Daraus folgt nun insbesondere $\phi(\exp(v))=\gamma(1)=\exp(\DD\phi\vert_e v)$.
			\end{proof}
		\end{lemma}
		\begin{bem}\label{bem:exp_induziert_Abbildungen}
			Aufgrund von Lemma \ref{lemma:Eigenschaften_exp} lassen sich also die induzierten Lie-Algebrenhomomorphismen $\DD\phi\vert_e$ wie folgt berechnen:
			\begin{align*}
				\DD\phi\vert_e v&=\frac{d}{dt}\exp(t \DD\phi\vert_e v)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\phi(\exp(tv))\Big\vert_{t=0}
			\end{align*}
		\end{bem}
	\section{Wirkungen und Darstellungen}
		\begin{defn}
			Sei $M$ eine Mannigfaltigkeit, $G$ eine Lie-Gruppe.
			
			Eine \emph{(Rechts-) Wirkung} ist eine Abbildung 
			\begin{gather*}
					\tril\colon M \times G \rightarrow M, \quad (p,g) \mapsto p\tril g 
				\intertext{die mit der Verknüpfung im folgenden Sinne kompatibel ist:}
					(p \tril g)\tril h = p\tril (g\cdot h) \quad \forall p\in M, g,h \in G
				\end{gather*}
				
				Analog definiert man eine \emph{(Links-) Wirkung} $\trir \colon G \times M \rightarrow M,\; (p,g)\mapsto g\trir p$, sodass 
				\begin{equation*}
					h\trir (g\trir p) =(h\cdot g)\trir p \quad \forall p\in M, g,h \in G
				\end{equation*}
				wobei die Reihenfolge umgekehrt ist.
				
				Eine \emph{Darstellung} ist eine Abbildung $\rho\colon G\rightarrow \GL(V)$ mit einem Vektorraum $V$, sodass $V\times G\rightarrow V, (v,g)\mapsto \rho(g)v$ eine Linkswirkung ist (also $\rho(g)\rho(h)=\rho(g\cdot h) \forall g,h\in G$).
		\end{defn}
		\begin{bsp}\hfill
			\begin{enumerate}
				\item Rechts- und Linkstranslationen sind Rechts- und Linkswirkungen auf der Lie-Gruppe selbst.
				\item Schreibt man die Elemente der obigen Beispiele von Lie-Gruppen in ihrer üblichen Form als $n\times n$-Matrizen, so erhält man (sogenannte fundamentale) Darstellungen durch die Matrixmultiplikation mit Elementen von $\R^n$ bzw. $\mathbb{C}^n$.
			\end{enumerate}
		\end{bsp}
		\begin{defn}[Die Adjungierte Darstellung]\hfill
		
			Die Konjugation liefert eine Darstellung jeder Lie-Gruppe auf ihrer Lie-Algebra, die sogenannte \emph{Adjungierte Darstellung}:
			\begin{align*}
				\Ad\colon G\rightarrow \GL(\mathfrak{g}), g\mapsto \DD c_g\vert_e
			\end{align*}
			Man erhält darüber hinaus auch eine Darstellung der Lie-Algebra selbst:
			\begin{align*}
				\ad:=\DD\Ad\vert_e\colon\mathfrak{g}\rightarrow\End(\mathfrak{g}),
			\end{align*}
			Mit Lemma \ref{lemma:Fluss_linksinvarianter_Vektorfelder} und Bemerkung \ref{bem:exp_induziert_Abbildungen} folgt dann:
			\begin{align*}
				\ad_v(w)&=\frac{d}{dt}\Ad_{\exp(tv)}(w)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD c_{\exp(tv)}\vert_e w\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD r_{\exp(-tv)}\vert_{\exp(tv)}\DD l_{\exp(tv)}\vert_e w\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD r_{\exp(-tv)}\vert_{\exp(tv)}L(w)_{\exp(tv)}\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\DD \Phi_{-t}^{L(v)}\vert_{\Phi^{L(v)}_t(e)}L(w)_{\Phi^{L(v)}_t(e)}\right)\Big\vert_{t=0}\\
				&=\frac{d}{dt}\left(\left(\Phi_{-t}^{L(v)}\right)_*L(w)\right)_e\Big\vert_{t=0}\\
				&=\mathcal{L}_{L(v)}(L(w))_e\\
				&=\left[v,w\right]
			\end{align*}
			Also ist $\ad_v$ eine lineare Abbildung. Beachte: $\ad$ ist auch \glqq im ersten Argument\grqq\ linear, also $\ad_{v+w}=\ad_v+\ad_w \quad\forall v,w\in\mathfrak{g}$ und ist damit ein Gruppenhomomorphismus der Lie-Algebra als additive Gruppe, allerdings keine Abbildung in eine $\GL(V)$ (Man sagt dennoch \glqq induzierte Darstellung\grqq).
		\end{defn}
		\begin{defn}[Killing-Form]
			Die \emph{Killing-Form} ist eine symmetrische Bilinearform, definiert durch:
			\begin{align*}
				B_{\mathfrak{g}}\colon\mathfrak{g}\times\mathfrak{g}\rightarrow\R, (v,w)\mapsto \tr(\ad_v\circ\ad_w).
			\end{align*}
			Die Bilinearität folgt aufgrund der Linearität der Spur und $\ad$ und die Symmetrie aufgrund der Zyklizität der Spur.
		\end{defn}
		\begin{satz}
			Die Killing-Form ist negativ definit genau dann, wenn die Lie-Gruppe kompakt und das Zentrum der Lie-Algebra
			\begin{equation*}
				\mathfrak{z}(\mathfrak{g}):=\lbrace v\in\mathfrak{g}\vert\, \left[v,w\right]=0\,\forall w\in\mathfrak{g}\rbrace
			\end{equation*}
			trivial ist.
		\end{satz}
		\kommB{Idee: Hier noch fundamentale Vektorfelder und adjungierte Darstellung und dann später bei Geodäten bzgl der Killing-form sehen, dass (die Exponentialabbildungen übereinstimmen und damit) die Geodäten gerade Integralkurven linksinvarianter Vektorfelder sind.}
		
		Mit Wirkungen lassen sich auch allgemeiner Vektorfelder von Elementen der Lie-Algebra erzeugen:
		\begin{defn}[Fundamentale Vektorfelder]
			Sei $\trir:G\times M\rightarrow M$ eine Linkswirkung.
			
			Das \emph{fundamentale Vektorfeld} $X^v$ zu einem Element der Lie-Algebra $v\in\mathfrak{g}$ ist durch die folgende Gleichung definiert:
			\begin{align*}
				X^v_p:=\frac{d}{dt}\exp(tv)\trir p\Big\vert_{t=0} \quad\forall p\in M
			\end{align*}
			Beachte, dass dies für die Linkstranslation gerade dem Fluss aus Lemma \ref{lemma:Fluss_linksinvarianter_Vektorfelder} entspricht!
		\end{defn}
		
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Tensorfelder}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Differentialformen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Kovariante Ableitungen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Riemann'sche Geometrie}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Integration auf Mannigfaltigkeiten}


\end{document}